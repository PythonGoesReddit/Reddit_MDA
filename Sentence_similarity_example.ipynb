{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import WordEmbeddings \n",
    "from flair.embeddings import FlairEmbeddings \n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static embeddings using glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using glove embedding\n",
    "GloVe_embedding = WordEmbeddings('glove')\n",
    "  \n",
    "# input a  sentence\n",
    "s = Sentence('Eye for an eye, tooth for a tooth.')\n",
    "  \n",
    "# embed the sentence\n",
    "GloVe_embedding.embed(s)\n",
    "  \n",
    "# print the embedded tokens\n",
    "for token in s:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dynamic embeddings with Flair "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # using forward flair embeddingembedding\n",
    "forward_flair_embedding= FlairEmbeddings('news-forward-fast')\n",
    "  \n",
    "# input the sentence\n",
    "s = Sentence('Eye for an eye, tooth for a tooth.')\n",
    "  \n",
    "# embed words in the input sentence\n",
    "forward_flair_embedding.embed(s)\n",
    "  \n",
    "# print the embedded tokens\n",
    "for token in s:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"He found a leprechaun in his walnut shell.\"\n",
    "]\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "print(sentence_embeddings.shape)\n",
    "\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33088914, 0.7219258 , 0.55483633]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(\n",
    "    [sentence_embeddings[0]],\n",
    "    sentence_embeddings[1:]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a sentence similarity model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "train_examples = [InputExample(texts=['My first sentence', 'My second sentence'], label=0.8),\n",
    "   InputExample(texts=['Another pair', 'Unrelated sentence'], label=0.3)]\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "915ec26a27f31d7a8db4bf03f6f41f87084598d7b314c76fa930970a9cbd09a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
