---
title: "Feature_documentation"
author: "Hanna Mahler"
date: "2023-10-01"
output: html_document
---

This R-Markdown contains a documentation of the linguistic features annotated by our Python script.
Most of the features are taken from Biber (1988), some are adapted from Clarke & Grieve (2017), and some are our own additions. 

For every feature we will first quote how it is defined in the original source (if known) and provide an example. We will then show how the feature is extracted in our code and what the extraction criteria are. If applicable, we will justify any deviations from the original source. We will also provide an accuracy measurement for each feature: an F-score that was calculated from the comparison of the automatic extraction with a manual coding of the feature in question.

Features that were dropped from the analysis can be found at the end of the file.

Note that the Python code included here is not meant to be run on its own. It is copied out of our main script "Reddit_MDA" and serves illustration purposes only.

*What still needs to be done:*
- add missing accuracy scores after next round of testing
- we often have the condition "if tagged_sentence[index-1][0] in ALLP" to catch sentence-initial structures. Should this not be " elif tagged_sentence[index-1][0] == "X"" ?? (same for sentence-final positions) -> if we decide to change this: update accuracy scores afterwards!
- add code for ttratio_043 to main script and in here.
- decide what to do with the features that had 0 hits in our sample data - keep them in the code without reporting an accuracy score? Or remove?
- decide what to do with whquest_013 and caps_204 (did not reach required accuracy level)
- complete the description for caps_204 (after Axel modified it)
- thatresub_029: are we missing the condition: item == "that" ?
- wordlength_044: what are we replacing here and why?
- whresub_031: do we have a hierarchy problem here? Condition that the noun needs to precede holds? Combine this and whreobj_032?
    - I think this is why this feature does so badly in the accuracy test.
- whreobj_032: do we have a hierarchy problem here? Condition that the noun needs to precede holds?
    - I think this is why this feature does so badly in the accuracy test.


## Verbs in the past tense: vpast_001

- Definition from Biber: "Any past tense form that occurs in the dictionary, or any word not otherwise identified that is longer than six letters and ends in ed%. Past tense forms have been edited by hand to distinguish between those forms with past participial functions and those with past tense functions." (1988: 223)
- Example from Reddit: San Francisco is in America in case you *forgot* LOL.
- Our search stragey: everything that received the tag "VBD" (verb in the past tense) within the function analyze_verb.
```{python}
    word_tuple = tagged_sentence[index]
    if word_tuple[1] == "VBD":
        features_dict["vpast_001"] += 1
```

- Accuracy: F-score of 0.75

## Verbs in the present perfect: vpresperfect_002a

- Definition from Biber: 
  "(a) HAVE + (ADV) + (ADV) + VBN 
  (b) HAVE+ N/PRO + VBN (questions) 
  (includes contracted forms of HAVE)" (1988: 223)
- Example from Reddit: There is no evolution, just a list of animals Chuck Norris *has allowed* to live. 
- Our search strategy: Biber's feature 2 "perfect aspect" does not distinguish between present perfect and past perfect. We therefore decided to split this up into two features (002a and 002b). For the present perfect we count combinations of ["have", "'ve", "has"] plus verbs with the tag "VBN" (past participle of verb) within the function analyze_verb. We are allowing for an unspecified number of intervening adverbs and nouns. 
```{python}
    elif word_tuple[0] in ["have", "'ve", "has"]: 
        move_on = True
        insert_adv = False
        x = index
        while move_on: 
            x += 1
            if tagged_sentence[x][1] == "VBN":
                move_on = False
                features_dict["vpresperfect_002a"] += 1
                if insert_adv:
                    features_dict["vsplitaux_063"] += 1
            elif tagged_sentence[x][1].startswith("R") and tagged_sentence[x][0] not in ["n't", "not"]:
                insert_adv = True
            elif tagged_sentence[x][1].startswith("N") or tagged_sentence[x][1].startswith("P"): 
                move_on = True
            else: 
                move_on = False
```

- Accuracy: F-score of 0.83


## Verbs in the past perfect: vpastperfect_002b

- Definition from Biber: 
  "(a) HAVE + (ADV) + (ADV) + VBN 
  (b) HAVE+ N/PRO +VBN (questions) 
  (includes contracted forms of HAVE)" (1988: 223)
- Example from Reddit: I *had* always *thought* they were great idea, [...] 
- Our search strategy: Biber's feature 2 "perfect aspect" does not distinguish between present perfect and past perfect. We therefore decided to split this up into two features (002a and 002b). For the past perfect we count combinations of ["had", "'d"] plus verbs with the tag "VBN" (past participle of verb) within the function analyze_verb. We are allowing for an unspecified number of intervening adverbs and nouns. 
```{python}
    if word_tuple[0] in ["had", "'d"]: 
        move_on = True
        insert_adv = False
        x = index
        while move_on:
            x += 1
            if tagged_sentence[x][1] == "VBN":
                move_on = False
                features_dict["vpastperfect_002b"] += 1
                if insert_adv:
                    features_dict["vsplitaux_063"] += 1
            elif tagged_sentence[x][1].startswith("R") and tagged_sentence[x][0] not in ["n't", "not"]:
                insert_adv = True
            elif tagged_sentence[x][1].startswith("N") or tagged_sentence[x][1].startswith("P"):
                move_on = True 
            else: 
                move_on =  False 
```

- Accuracy: F-score of 0.60

## Verbs in the present tense: vpresent_003

- Definition from Biber: "All VB (base form) or VBZ (third person singular present) verb forms in the dictionary, excluding infinitives." (1988: 224)
- Example from Reddit: Dont even *care* about this game anymore. 
- Our search stragey: Within the function analyze_verb we are counting everything with the tag "VBP" (Verb, non-3rd person singular present ) or "VBZ" (Verb, 3rd person singular present ).
```{python}
    elif word_tuple[1] in ["VBP","VBZ"]:
        features_dict["vpresent_003"] += 1
```

- Accuracy: F-score of 0.89

## Place adverbials: advplace_004

- Definition from Biber: aboard, above, abroad, across, ahead, alongside, around, ashore, astern, away, behind, below, beneath, beside, downhill, downstairs, downstream, east, far, hereabouts, indoors, inland, inshore, inside, locally, near, nearby, north, nowhere, outdoors, outside, overboard, overland, overseas, south, underfoot, underground, underneath, uphill, upstairs, upstream, west (1988: 224)
- Example from Reddit: *Below* it on the same side is what TCL/BlackBerry are calling a [...]
- Our search stragey: Within the function analyze_adverb we are counting everything that is in our list of place adverbials, "placelist". This list is defined beforehand and contains all the items listed by Biber (no further additions).
```{python}
placelist = ["aboard", "above", "abroad", "across", "ahead", "alongside", "anywhere", "ashore", "astern", "away", "behind", "below", "beneath", "between", "beyond", "beside", "down", "downhill", "downstairs", "downstream", "downwind", "east", "eastward", "eastwards", "elsewhere", "everywhere", "far", "here", "hereabouts", "indoors", "inland", "inshore", "inside", "locally", "near", "nearby", "north", "northward", "northwards", "nowhere", "offshore", "opposite", "outdoors", "outside", "overboard", "overhead", "overland", "overseas", "somewhere", "south", "southward", "southwards", "there", "thereabouts", "through", "throughout", "under", "underfoot", "underground", "underneath", "uphill", "upstairs", "upstream", "west", "westward", "westwards", "within"] 

    elif word_tuple[0] in placelist:
        features_dict["advplace_004"] += 1
```

- Accuracy: F-score of 1.00

## Time adverbials on location in time: advtime_position_005a

- Definition from Biber: "afterwards, again, earlier, early, eventually, formerly, immediately, initially, instantly, late, lately, later, momentarily, now, nowadays, once, originally, presently, previously, recently, shortly, simultaneously, soon, subsequently, today, tomorrow, tonight, yesterday" (1988: 224)
- Example from Reddit: *Now* if we're talking about lavo, ovo or lavo-ovo vegetarians, yes, [...]
- Our search strategy: Biber's feature 5, "time adverbials" does not distinguish between adverbials relating to a specific point in time (e.g. "yesterday") and adverbials relating to the frequency of occurrence or duration of an event (e.g. "daily"). We therefore decided to split this feature into two, 005a and 005b. For advtime_position_005a we are looking for items that are in the list "timepoints" within the function analyze_adverb. This list was defined beforehand. 
```{python}
timepoints = ["afterwards", "again", "already", "anymore", "before", "currently", "earlier", "early", "eventually", "formerly", "finally", "immediately", "initially", "instantly", "late", "lately", "later", "momentarily", "now", "nowadays",  "originally", "presently", "previously", "promptly", "recently", "shortly", "simultaneously", "soon", "subsequently", "today", "tomorrow", "tonight", "yesterday"]

    elif word_tuple[0] in timepoints:
        features_dict["advtime_position_005a"] += 1
```

- Accuracy: F-score of 0.90

## Time adverbials on frequency: advtime_durfreq_005b

- Definition from Biber: "afterwards, again, earlier, early, eventually, formerly, immediately, initially, instantly, late, lately, later, momentarily, now, nowadays, once, originally, presently, previously, recently, shortly, simultaneously, soon, subsequently, today, tomorrow, tonight, yesterday" (1988: 224)
- Example from Reddit: I think the boxes *usually* ask for oil but you can use the exact same amount in butter.
- Our search strategy: Biber's feature 5, "time adverbials" does not distinguish between adverbials relating to a specific point in time (e.g. "yesterday") and adverbials relating to the frequency of occurrence or duration of an event (e.g. "daily"). We therefore decided to split this feature into two, 005a and 005b. For advtime_durfreq_005b we are looking for items that are in the list "timedurfreq" within the function analyze_adverb. This list was defined beforehand. 
```{python}
timedurfreq = ["always", "annually", "ceaselessly", "commonly", "constantly", "continually", "continuously", "customarily", "daily", "eternally", "evermore", "endlessly", "forever", "fortnightly", "frequently", "habitually", "hourly", "infrequently", "intermittently", "irregularly", "invariably", "monthly", "never", "occasionally", "often", "oftentimes", "once", "periodically", "perpetually", "persistently", "rarely", "repeatedly", "routinely", "seldom", "sometimes", "twice", "unceasingly", "usually","weekly", "yearly"]

    elif word_tuple[0] in timedurfreq:
        features_dict["advtime_durfreq_005b"] += 1
```

- Accuracy: F-score of 0.80

## First-person pronouns: profirpers_006

- Definition from Biber: "I, me, we, us, my, our, myself, ourselves (plus contracted forms)" (1988: 225)
- Example from Reddit: Cool, just let *me* know if you change your mind
- Our search strategy: Within the function analyze_pronoun we are looking for everything that is part of the list "firstpersonlist". This list was defined beforehand, it contains the same items as listed in Biber.
```{python}
firstpersonlist = ["i", "me", "we", "us", "my", "our", "myself", "ourselves"]

    elif word_tuple[0] in firstpersonlist:
        features_dict["profirpers_006"] += 1
```

- Accuracy: F-score of 0.96

## Second-person pronouns: prosecpers_007

- Definition from Biber: "you, your, yourself, yourselves (plus contracted forms)" (1988: 225)
- Example from Reddit: *You* sound like a smug asshole that likes the smell of his own farts. 
- Our search strategy: Within the function analyze_pronoun we are counting everything that is part of the lsit "secondpersonlist". This list was defined beforehand and contains the same items as mentioned in Biber.
```{python}
secondpersonlist = ["you", "yourself", "your", "yourselves"]

    elif word_tuple[0] in secondpersonlist:
        features_dict["prosecpers_007"] += 1
```

- Accuracy: F-score of 1.00

## Third-person pronouns: prothirper_008

- Definition from Biber: "she, he, they, her, him, them, his, their, himself, herself, themselves (plus contracted forms)" (1988: 225)
- Example from Reddit: People who want a cap in *their* ass that's who.
- Our search strategy: Within the function analyze_pronoun we are counting everything that is in the list "thirdpersonlist". This list was defined beforehand and contains the same items as listed in Biber.
```{python}
thirdpersonlist = ["she", "he", "they", "her", "him", "them", "his", "their", "himself","herself", "themselves"]

    elif word_tuple[0] in thirdpersonlist:
        features_dict["prothirdper_008"] += 1
```

- Accuracy: F-score of 1.00

## Pronoun 'it': proit_009

- Definition from Biber: not stated, presumably surface form "it" (1988: 225-226)
- Example from Reddit: Not much of a comment, I know, but *it*'s hard to comment on a story that I don't find interesting. 
- Our search strategy: Within the function analyze_pronoun we are counting everything with the surface form "it".
```{python}
    if word_tuple[0] == "it":
        features_dict["proit_009"] += 1
```

- Accuracy: F-score of 0.97

## Demonstrative pronouns: prodemons_010

- Definition from Biber: 
  "(a) that/this/these/those + V/AUX/CL-P/TS/WHP/W (where that is not a relative pronoun) 
  (b) that's 
  (c) T# + that 
  (that in this last context was edited by hand to distinguish among demonstrative pronouns, relative pronouns, complementizers, etc.)" (1988: 226)
- Example from Reddit: *That*'s not Samuel l Jackson? 
- Our search strategy: We first distinguish between ["this", "these", "those"] and the word "that", since "that" has more potential functions in the sentence. We then check whether the following item (with a potential intervening adjective) is a noun to sort out demonstrative determiners (see feature demonstr_051). All remaining items are counted as demonstrative pronouns. This is a slight deviation from Biber's approach. We included this code chunk within the function analyze_pronoun and within analyze_determiner to make sure we catch all cases, irrespective of the POS-tag that was assigned. 
```{python}
    if word_tuple[0] in ["this", "these", "those"]:
        if tagged_sentence[index+1][1].startswith("NN"):
            features_dict["demonstr_051"] += 1
        elif tagged_sentence[index+1][1].startswith("JJ") and tagged_sentence[index+2][1].startswith("NN"):
            features_dict["demonstr_051"] += 1
        else:
            features_dict["prodemons_010"] += 1

    if word_tuple [0] == "that":
        if tagged_sentence[index+1][1].startswith("NN"):
            features_dict["demonstr_051"] += 1
        elif tagged_sentence[index+1][1].startswith("JJ") and tagged_sentence[index+2][1].startswith("NN"):
            features_dict["demonstr_051"] += 1
        elif tagged_sentence[index+1][0] == "X":
            features_dict["prodemons_010"] += 1
        elif tagged_sentence[index+1][1].startswith("JJ"):
            features_dict["prodemons_010"] += 0
        else:
            features_dict["prodemons_010"] += 1
```

- Accuracy: F-score of 0.78

## Indefinitve pronouns: proindef_011

- Definition from Biber: "anybody, anyone, anything, everybody, everyone, everything, nobody, none, nothing, nowhere, somebody, someone, something" (1988: 226)
- Example from Reddit: I agree, why would *anyone* outside a marketing department create a giant poster with such a bad pun. 
- Our search strategy: We count everything that is in the list "indefpronounlist", which was defined above. The list contains the same items as given by Biber. We included this code within the analyze_noun function and the analyze_pronoun function, because the tagger seemed to be slightly inconsistent in its assignment.
```{python}
indefpronounlist = ["anybody", "anyone", "anything", "everybody", "everyone", "everything", "nobody", "none", "nothing", "nowhere", "somebody", "someone", "something"]

    if word_tuple[0] in indefpronounlist:
        features_dict["proindef_011"] += 1
```

- Accuracy: F-score of 1.00

## Pro-verb do: pverbdo_012

- Definition from Biber: "DO when NOT in the following constructions: 
  DO + (ADV) + V      (DO as auxiliary) 
  ALL-P/TS/WHP + DO   (DO as question)" (1988: 226)
- Example from Reddit: But when you *do*, he will definitely score for you. 
- Our search strategy: Within the function analyze_verb we are first checking for forms of 'do'. Then we are only counting instances that are in sentence-final position, or that are followed by ["too", "this", "that", "it", "so"] in sentence-final position. This is a slight deviation from Biber's strategy.
```{python}
dolist = ["do", "does", "doing", "did", "done"]

    if word_tuple[0] in dolist:
        if tagged_sentence[index+1][1] == "X" or tagged_sentence[index+1][0] in ALLP:
            features_dict["pverbdo_012"] += 1
        elif tagged_sentence[index+1][0] in ["too", "this", "that", "it", "so"]:
            if tagged_sentence[index+2][1] == "X" or tagged_sentence[index+2][0] in ALLP:
                features_dict["pverbdo_012"] += 1
            else:
                pass
```

- Accuracy: F-score of 0.74

## WH-questions: whquest_013

- Definition from Biber: "CL-P/Tif + WHO + AUX (where AUX is not part of a contracted form)" (1988: 227)
- Example from Reddit: If Redskins get Williams...*where* is he playing?
- Our search strategy: Within the function analyze_wh_word we first select all items that have the tag "WRB" (wh-adverbs) and that occur in sentence-initial position or after punctuation. We count all structures that have a modal verb following ("Where will he go?"). We also count structure that have a form of 'be', 'have', or 'do' following ("When are you leaving?"). Out of all remaining structures we also count those that have "who" as wh-word, that have "what about", or that include the insertion "the hell" or "the fuck".
  We decided to use the tag "WRB" instead of Biber's condition (part of "WHO") because it consistently identifies interrogative particles, including "who" if and only if it is an interrogative particle. We also decided that we want to look not only for sentence-initial uses, but for anything following clause-level punctuation (we use the tag "SYM" for that).
```{python}
        if word_tuple[1] == "WRB":
            if tagged_sentence[index-1][1] in ["X", "SYM"]:  
                if tagged_sentence[index+1][1] == "MD":
                    features_dict["whquest_013"] += 1
            elif tagged_sentence[index+1][1].startswith("V"):
                if tagged_sentence[index+1][0] in belist or tagged_sentence[index+1][0] in havelist or tagged_sentence[index+1][0] in dolist:
                    features_dict["whquest_013"] += 1
                elif word_tuple[0] == "who":
                    features_dict["whquest_013"] += 1
                elif tagged_sentence[index+1] == "the" and tagged_sentence[index+2] in ["hell", "fuck"]:
                    features_dict["whquest_013"] += 1
                elif word_tuple[0] == "what" and tagged_sentence[index+1][0] == "about":
                    features_dict["whquest_013"] += 1
```

- Accuracy: F-score of 

## Nominalisations: nominalis_014

- Definition from Biber: "All words ending in -tion#, -ment#, -ness#, or -ity# (plus plural forms)" (1988: 227)
- Example from Reddit: Denial that racism exists and how most people discuss it on a public forum could also be considered a mental *illness*.
- Our search strategy: Within the function analyze_noun we are checking for items that end in certain suffixes (same list as given in Biber).
```{python}
    elif word_tuple[0].endswith("tions") or word_tuple[0].endswith("tion") or word_tuple[0].endswith("ments") or word_tuple[0].endswith("ment") or word_tuple[0].endswith("ness") or word_tuple[0].endswith("ity") or word_tuple[0].endswith("nesses") or word_tuple[0].endswith("ities"):
        features_dict["nominalis_014"] += 1
```

- Accuracy: F-score of 0.71

## Nouns: nouns_016

- Definition from Biber: "All nouns included in the dictionary, excluding those forms counted as nominalizations or gerunds." (1988: 228)
- Example from Reddit: Good *lesson*.
- Our search strategy: Within the function analyze_nouns we are counting all items that were not previously identified as gerunds or nominalisations or indefinite pronouns. These are the same criteria as in Biber, except for the indefinite pronouns (which he does not mention).
```{python}
    if word_tuple[0] in indefpronounlist:
        features_dict["proindef_011"] += 1
    if word_tuple[0].endswith("ing"): # or word_tuple[0].endswith("ings"): # removing plural form since gerund nouns only accept sing
        if word_tuple[0] not in notgerundlist:
            features_dict["gerund_015"] += 1
    elif word_tuple[0].endswith("tions") or word_tuple[0].endswith("tion") or word_tuple[0].endswith("ments") or word_tuple[0].endswith("ment") or word_tuple[0].endswith("ness") or word_tuple[0].endswith("ity") or word_tuple[0].endswith("nesses") or word_tuple[0].endswith("ities"):
        features_dict["nominalis_014"] += 1
    else: 
        features_dict["nouns_016"] += 1
```

- Accuracy: F-score of 1.00

## Agentless passives: passagentl_017

- Definition from Biber: 
  "(a) BE + (ADV) + (ADV) + VBN 
  (b) BE + N/PRO + VBN  (question form)" (1988: 228)
- Example from Reddit: Your submission *has been* automatically *removed* because you haven't registered with our steam bot to receive flair.
- Our search strategy: Our search strategy here might look rather complex. We are within the function analyze_verb and we implement two different checks. 
  - Check 1: We first check whether the item itself is a form of "be". The item needs to be either in sentence-initial position or following a wh-adverb ("WRB") in sentence-initial position (to include wh-questions such as "How was the parcel delivered?"). We then count all instances as agentless passives that have a past participle verb ("VBN") within the next five words and no trace of a by-phrase.
  - Check 2: We first check whether the item itself is a form of "be") and eliminate uses as a main verb. Within all remaining structures we count everything that has a past participle following without a by-phrase in the next position.
```{python}
belist = ["be", "am", "are", "is", "was", "were", "been", "being", "'m", "'re"]

    elif word_tuple[0] in belist and (index == 3 or (index == 4 and tagged_sentence[index-1][1] == "WRB")): # Questions with BE; the index positions take the three ("x", "x") tuples at the beginning of a sentence into account
         add_index = 0
         while add_index < 5 and (index + add_index) < (len(tagged_sentence)-1):
             add_index+=1
             if tagged_sentence[index+add_index][1] == "VBN":
                 if tagged_sentence[index+add_index+1][0] == "by":
                     features_dict["passby_018"] += 1
                 else:
                     features_dict["passagentl_017"] += 1    
                     
    elif word_tuple[0] in belist:
        if tagged_sentence[index+1][1] in ["DT", "PRP$", "JJ", "JJR", "JJS", "NN", "NNS", "NNP"]:
            features_dict["mainvbe_019"] += 1
        elif tagged_sentence[index+1][1] == "RB" and tagged_sentence[index+2][1] in ["DT", "PRP$", "JJ", "JJR", "JJS", "NN", "NNS", "NNP"]:
            features_dict["mainvbe_019"] += 1
            
        else:
            move_on = True
            insert_adv = False
            x = index
            while move_on == True:
                x += 1
                if tagged_sentence[x][1] == "VBN":
                    move_on = False
                    if tagged_sentence[x+1][0] == "by":
                        features_dict["passby_018"] += 1
                        if insert_adv:
                            features_dict["vsplitaux_063"] += 1
                    elif tagged_sentence[x+1][1] == "IN": # Here, provision is made for by-passive with intervening PPs: "was shot in the head by an unidentified suspect"
                        x += 1
                        move_on2 = True
                        while move_on2:
                            x += 1
                            if tagged_sentence[x+1][1].startswith("N") or tagged_sentence[x+1][1].startswith("DT"):
                                pass
                            elif tagged_sentence[x+1][0] == "by":
                                features_dict["passby_018"] += 1
                                if insert_adv:
                                    features_dict["vsplitaux_063"] += 1
                                move_on2 = False
                            else:
                                features_dict["passagentl_017"] += 1
                                if insert_adv:
                                    features_dict["vsplitaux_063"] += 1
                                move_on2 = False
                    else:
                        features_dict["passagentl_017"] += 1
                        if insert_adv:
                            features_dict["vsplitaux_063"] += 1  
                elif tagged_sentence[x][1].startswith("RB"):
                    if tagged_sentence[x][0] not in ["n't", "not"]:
                        insert_adv = True
                    else:
                        pass
                else:
                    move_on = False
```

- Accuracy: F-score of 0.82

## By-passives: passby_018

- Definition from Biber: 
  "(a) BE + (ADV) + (ADV) + VBN + by 
  (b) BE + N/PRO + VBN + by (question form)" (1988: 228)
- Example from Reddit: [...] the joke that the latest Bin Laden "message" *has been manufactured* by Mediaset in Milan [...] 
- Our search strategy: Our search strategy here might look rather complex. We are within the function analyze_verb and we implement two different checks. 
  - Check 1: We first check whether the item itself is a form of "be". The item needs to be either in sentence-initial position or following a wh-adverb ("WRB") in sentence-initial position (to include wh-questions such as "When was the food delivered by the driever?"). We then count all instances as by-passives that have a past participle verb ("VBN") within the next five words and a by-phrase following immediately afterwards.
  - Check 2: We first check whether the item itself is a form of "be") and eliminate uses as a main verb. Within all remaining structures we count everything that has a past participle following and a by-phrase in the next position. We also allow for a prepositional phrase intervening between the verb and the by-phrase ("The food was delivered at lunchtime by the driever"). 
  We therefore include more structures than Biber does.
```{python}
    elif word_tuple[0] in belist and (index == 3 or (index == 4 and tagged_sentence[index-1][1] == "WRB")): # Questions with BE; the index positions take the three ("x", "x") tuples at the beginning of a sentence into account
         add_index = 0
         while add_index < 5 and (index + add_index) < (len(tagged_sentence)-1):
             add_index+=1
             if tagged_sentence[index+add_index][1] == "VBN":
                 if tagged_sentence[index+add_index+1][0] == "by":
                     features_dict["passby_018"] += 1
                 else:
                     features_dict["passagentl_017"] += 1    
    elif word_tuple[0] in belist:
        if tagged_sentence[index+1][1] in ["DT", "PRP$", "JJ", "JJR", "JJS", "NN", "NNS", "NNP"]:
            features_dict["mainvbe_019"] += 1
        ## allow for one intervening adverb for mainvbe_019
        elif tagged_sentence[index+1][1] == "RB" and tagged_sentence[index+2][1] in ["DT", "PRP$", "JJ", "JJR", "JJS", "NN", "NNS", "NNP"]:
            features_dict["mainvbe_019"] += 1
            
        else:
            move_on = True
            insert_adv = False
            x = index
            while move_on == True:
                x += 1
                if tagged_sentence[x][1] == "VBN":
                    move_on = False
                    if tagged_sentence[x+1][0] == "by":
                        features_dict["passby_018"] += 1
                        if insert_adv:
                            features_dict["vsplitaux_063"] += 1
                    elif tagged_sentence[x+1][1] == "IN": # Here, provision is made for by-passive with intervening PPs: "was shot in the head by an unidentified suspect"
                        x += 1
                        move_on2 = True
                        while move_on2:
                            x += 1
                            if tagged_sentence[x+1][1].startswith("N") or tagged_sentence[x+1][1].startswith("DT"): # One might include adjectives here as well, but prob at the cost of precision.
                                pass
                            elif tagged_sentence[x+1][0] == "by":
                                features_dict["passby_018"] += 1
                                if insert_adv:
                                    features_dict["vsplitaux_063"] += 1
                                move_on2 = False
                            else:
                                features_dict["passagentl_017"] += 1
                                if insert_adv:
                                    features_dict["vsplitaux_063"] += 1
                                move_on2 = False
                    else:
                        features_dict["passagentl_017"] += 1
                        if insert_adv:
                            features_dict["vsplitaux_063"] += 1  
                elif tagged_sentence[x][1].startswith("RB"):
                    if tagged_sentence[x][0] not in ["n't", "not"]:
                        insert_adv = True
                    else:
                        pass
                else:
                    move_on = False
```

- Accuracy: F-score of 0.71

## Main verb use of be: mainvbe_019

- Definition from Biber: "BE + DET/POSSPRO/TITLE/PREP/ADJ" (1988: 229)
- Example from Reddit: Also, they*'re* fake. 
- Our search strategy: Within the function analyze_verb we first check whether the item is part of "belist". The list is defined beforehand and contains full and contracted forms of 'be' (except for 's which can serve several functions). We count the structure towards mainvbe_019 if the following item is tagged as ["DT", "PRP$", "JJ", "JJR", "JJS", "NN", "NNS", "NNP"] (with one potential intervening adverbial). We then repeat these steps for all items with the surface form 's (since we don't want this as part of our "belist", which is used in several other functions). We therefore deviate from Biber in allowing for intervening adverbials and by giving special attention to 's (which is not part of Biber's list for "BE"). 
```{python}
belist = ["be", "am", "are", "is", "was", "were", "been", "being", "'m", "'re",]

    elif word_tuple[0] in belist:
        if tagged_sentence[index+1][1] in ["DT", "PRP$", "JJ", "JJR", "JJS", "NN", "NNS", "NNP"]:
            features_dict["mainvbe_019"] += 1
        elif tagged_sentence[index+1][1] == "RB" and tagged_sentence[index+2][1] in ["DT", "PRP$", "JJ", "JJR", "JJS", "NN", "NNS", "NNP"]:
            features_dict["mainvbe_019"] += 1

    if word_tuple[0] == "'s" or word_tuple[0] == "s":
        if tagged_sentence[index+1][1] in ["DT", "PRP$", "JJ", "JJR", "JJS", "NN", "NNS", "NNP"]:
            features_dict["mainvbe_019"] += 1
        elif tagged_sentence[index+1][1] == "RB" and tagged_sentence[index+2][1] in ["DT", "PRP$", "JJ", "JJR", "JJS", "NN", "NNS", "NNP"]:
            features_dict["mainvbe_019"] += 1
```

- Accuracy: F-score of 0.80

## Exitential 'there': exthere_020

- Definition from Biber: 
  "(a) there + (xxx) + BE 
  (b) there's" (1988: 229)
- Example from Reddit: I just wished *there* was other UHQ pics from that photoshoot.. Closeups would be nice too! 
- Our search strategy: Within the function analyze_there we count everything with the tag "EX" (tag for existential there). We are therefore not implementing Biber's conditions, since the tag set contains a special tag for existential there.
```{python}
    if tagged_sentence[index][1] == "EX":
        features_dict["exthere_020"] += 1 
```

- Accuracy: F-score of 0.95

## 'that' verb complements thatvcom_021

- Definition from Biber: 
  "(a) and/nor/but/or/also/ALL-P + that + DET/PRO/there/plural noun/proper noun/TITLE (these are that-clauses in clause-initial positions) 
  (b) PUB/PRV/SUA/SEEM/APPEAR + that + xxx (where xxx is NOT: V/AUX/CL-P/T#/and) (that-clauses as complements to verbs which are not included in the above verb classes are not counted - see Quirk et al. 1985:1179ff.) 
  (c) PUB/PRV/SUA + PREP + xxx + N + that (where xxx is any number of words, but NOT = N) (This algorithm allows an intervening prepositional phrase between a verb and its complement.) 
  (d) T# + that (This algorithm applies only to spoken texts. Forms in this context are checked by hand, to distinguish among that complements, relatives, demonstrative pronouns and subordinators.)" (1988: 230)
- Example from Reddit: Movies and TV shows have shown *that* weapon movement is independent from head movement. 
- Our search strategy: Within the function analyze_preposition we first check whether the item is "that". If yes, we count the structure if it is in sentence-initial position or preceded by ["and", "nor", "but", "or", "who"], and it is followed by a noun phrase or title or the word "there". Alternatively, we count the structure if it is preceded by public, private, or suasive verb (or a form of 'seem' or 'appear'), and the item is not followed by "and", a verb or sentence-final punctuation.
  We decided against implementing Biber's condition c) as it seems marginal to us and complicated to count correctly.
```{python}
    if tagged_sentence[index][0] == "that":
    # (a) and\nor\but\or\aho\ALL-P + that + DET/PRO/there/plural noun/proper noun/TITLE (these are i/za£-clauses in clause-initial positions)
        if tagged_sentence[index-1][0] in ALLP or tagged_sentence[index-1][0] in ["and", "nor", "but", "or", "who"]:
            if tagged_sentence[index+1][1] in ["DT", "PRP", "NNS", "NNP"] or tagged_sentence[index+1][0] in titlelist or tagged_sentence[index+1][0] == "there":
                features_dict["thatvcom_021"] += 1
    # (b) PUB/PRV/SUA/SEEM/APPEAR + that + xxx (where xxx is NOT: V/AUX/CL-P/and)
        elif (tagged_sentence[index-1][0] in suasivelist) or (tagged_sentence[index-1][0] in privatelist) or (tagged_sentence[index-1][0] in publiclist):
            if not tagged_sentence[index+1][1].startswith("V"):
                if tagged_sentence[index+1][0] not in [ALLP, "and"]:
                    features_dict["thatvcom_021"] += 1
        elif (tagged_sentence[index-1][0].startswith("seem")) or (tagged_sentence[index-1][0].startswith("appear")):
            if not tagged_sentence[index+1][1].startswith("V"):
                if tagged_sentence[index+1][0] not in [ALLP, "and"]:
                    features_dict["thatvcom_021"] += 1            

```

- Accuracy: F-score of 0.80

## 'that' adjective complements thatacom_022

- Definition from Biber: "ADJ + (T#) + that (complements across intonation boundaries were edited by hand)" (1988: 231)
- Example from Reddit: I live in the country of reddit and I feel absolutely lucky *that* I see these exotic views everymorning.
- Our search strategy: Within the function analyze_preposition we count all cases where the item has the surface form "that" and the preceding item is tagged as an adjective. We sort out cases of verbal complementation beforehand.
```{python}
    if tagged_sentence[index][0] == "that":
        if tagged_sentence[index-1][0] in ALLP or tagged_sentence[index-1][0] in ["and", "nor", "but", "or", "who"]:
            if tagged_sentence[index+1][1] in ["DT", "PRP", "NNS", "NNP"] or tagged_sentence[index+1][0] in titlelist or tagged_sentence[index+1][0] == "there":
                features_dict["thatvcom_021"] += 1
        elif (tagged_sentence[index-1][0] in suasivelist) or (tagged_sentence[index-1][0] in privatelist) or (tagged_sentence[index-1][0] in publiclist):
            if not tagged_sentence[index+1][1].startswith("V"):
                if tagged_sentence[index+1][0] not in [ALLP, "and"]:
                    features_dict["thatvcom_021"] += 1
        elif (tagged_sentence[index-1][0].startswith("seem")) or (tagged_sentence[index-1][0].startswith("appear")):
            if not tagged_sentence[index+1][1].startswith("V"):
                if tagged_sentence[index+1][0] not in [ALLP, "and"]:
                    features_dict["thatvcom_021"] += 1            
        if tagged_sentence[index-1][1].startswith("J"):
            features_dict["thatacom_022"] += 1 
```

- Accuracy: F-score of 0.73

## WH-clauses: whclause_023

- Definition from Biber: "PUB/PRV/SUA + WHP/WHO + xxx (where xxx is NOT = AUX - this excludes WH questions)" (1988: 231)
- Example from Reddit: When the time comes, you will remember *where* to go.
- Our search strategy: Within the function analyze_verb we first select only cases in which the verb is a public verb (part of the list "publiclist" defined beforehand). If yes, we first exclude cases of that-deletion. If the following item is part of the list WHP or WHO (see definition below), and the item after that is not a modal verb we count it towards whclause_023. 
  This procedure is repeated for private verbs and suasive verbs.
```{python}
WHP = ["who", "whom", "whose", "which"]
WHO = ["what", "where", "when", "how", "whether", "why", "whoever", "whomever", "whichever", "whenever", "whatever", "however"] 

    if word_tuple[0] in publiclist:
        features_dict["vpublic_055"] += 1
        if tagged_sentence[index + 1][0] in ["this", "these", "those", "I", "we", "he", "she", "they"]:
            features_dict["thatdel_060"] += 1
        elif tagged_sentence[index + 1][1].startswith("NN") or tagged_sentence[index + 1][1].startswith("PR"):
            if tagged_sentence[index + 2][1].startswith("V") or tagged_sentence[index + 2][1] == "MD":
                features_dict["thatdel_060"] += 1
        elif tagged_sentence[index + 1][1] in ["JJ", "JJR", "JJS", "RB", "RBR", "RBS", "PRP$", "DT"]:
            if tagged_sentence[index + 2][1].startswith("NN"):
                if tagged_sentence[index + 3][1].startswith("V") or tagged_sentence[index + 3][1] == "MD":
                    features_dict["thatdel_060"] += 1
        if tagged_sentence[index + 1][0] in WHP or tagged_sentence[index + 1][0] in WHO:
            if tagged_sentence[index + 2][1] != "MD":
                features_dict["whclause_023"] += 1
            else:
                pass
              
    if word_tuple[0] in privatelist:
        features_dict["vprivate_056"] += 1
        if tagged_sentence[index + 1][0] in ["this", "these", "that", "those", "I", "we", "he", "she", "they"]:
            features_dict["thatdel_060"] += 1
        elif tagged_sentence[index + 1][1].startswith("NN") or tagged_sentence[index + 1][1].startswith("PR"):
            if tagged_sentence[index + 2][1].startswith("V") or tagged_sentence[index + 2][1] == "MD":
                features_dict["thatdel_060"] += 1
        elif tagged_sentence[index + 1][1] in ["JJ", "JJR", "JJS", "RB", "RBR", "RBS", "PRP$", "DT"]:
            if tagged_sentence[index + 2][1].startswith("NN"):
                if tagged_sentence[index + 3][1].startswith("V") or tagged_sentence[index + 3][1] == "MD":
                    features_dict["thatdel_060"] += 1
        if tagged_sentence[index + 1][0] in WHP or tagged_sentence[index + 1][0] in WHO:
            if tagged_sentence[index + 2][1] != "MD":
                features_dict["whclause_023"] += 1
            else:
                pass

    if word_tuple[0] in suasivelist:
        features_dict["vsuasive_057"] += 1
        if tagged_sentence[index + 1][0] in ["this", "these", "that", "those", "I", "we", "he", "she", "they"]:
            features_dict["thatdel_060"] += 1
        elif tagged_sentence[index + 1][1].startswith("NN") or tagged_sentence[index + 1][1].startswith("PR"):
            if tagged_sentence[index + 2][1].startswith("V") or tagged_sentence[index + 2][1] == "MD":
                features_dict["thatdel_060"] += 1
        elif tagged_sentence[index + 1][1] in ["JJ", "JJR", "JJS", "RB", "RBR", "RBS", "PRP$", "DT"]:
            if tagged_sentence[index + 2][1].startswith("NN"):
                if tagged_sentence[index + 3][1].startswith("V") or tagged_sentence[index + 3][1] == "MD":
                    features_dict["thatdel_060"] += 1
        if tagged_sentence[index + 1][0] in WHP or tagged_sentence[index + 1][0] in WHO:
            if tagged_sentence[index + 2][1] != "MD":
                features_dict["whclause_023"] += 1
            else:
                pass
            
```

- Accuracy: F-score of 

## Verbs in the infinitive: vinfinitive_024

- Definition from Biber: "to + (ADV) + VB" (1988: 232)
- Example from Reddit: oh crap, that's right, need *to update* my links.
- Our search strategy: Within the function analyze_verb we first check for items tagges as VB (Verb, base form). We exclude all items in sentence-initial position or items following a comma. All remaining items are counted. We deviate from Biber in that we are not checking for the particle "to" to occur one or two to the left, since we rely on the tagger to correctly identify infinitives. 
```{python}
    elif word_tuple[1] == "VB":
        if tagged_sentence[index-1][1] == "X" or tagged_sentence[index-1][0] == ",": 
            features_dict["vimperative_205"] += 1
        else: 
            features_dict["vinfinitive_024"] += 1
```

- Accuracy: F-score of 0.67

## Past participial clauses: vpastpart_026

- Definition from Biber: "T#/ALL-P + VBN + PREP/ADV (these forms were edited by hand)" (1988: 233)
- Example from Reddit: *none in our sample data*
- Our search strategy: Within the function analyze_verb we are first looking for items with the tag "VBN" (Verb, past participle). The word is counted towards this feature if it is sentence-initial position and the following item is tagged as ["IN", "RB", "TO"]. We are therefore implementing the same strategy as Biber.
```{python}
    elif word_tuple[1] == "VBN":
        if (tagged_sentence[index-1][1] == "X" or tagged_sentence[index-1][0] in ALLP):
            if tagged_sentence[index+1][1] in ["IN", "RB", "TO"]:
                features_dict["vpastpart_026"] += 1
```

- Accuracy: F-score of 

## that-relative clauses on subject position: thatresub_029

- Definition from Biber: "N + (T#) + that + (ADV) + AUX/V (that relatives across intonation boundaries are identified by hand.)" (1988: 234)
- Example from Reddit: I’m sure you could work a persona *that* didn’t have a pretty scowl… &gt;:-D
- Our search strategy: Within the function analyze_wh_word we first check whether the preceding item has a nominal tag (all nominal tags start with "NN"). If yes we check whether the next item is a full verb or a modal verb. If these conditions are fulfilled the structure is counted towards the feature. We are also allowing for one intervening adverb (RB).
```{python}
    if tagged_sentence[index-1][1].startswith("NN"):
        if tagged_sentence[index+1][1].startswith("RB"):
            if (tagged_sentence[index+2][1].startswith("V") or tagged_sentence[index+2][1].startswith("MD")):
                features_dict["thatresub_029"] += 1 
        elif tagged_sentence[index+1][1].startswith("VB") or tagged_sentence[index+1][1].startswith("MD"):
            features_dict["thatresub_029"] += 1
```

- Accuracy: F-score of 0.71

## WH-relative clauses on subject position: whresub_031

- Definition from Biber: "xxx + yyy + N + WHP + (ADV) + AUX/V (where xxx is NOT any form of the verbs ASK or TELL; to exclude indirect WH questions like Tom asked the man who went to the store)" (1988: 235)
- Example from Reddit: You really want help go to an al-anon meeting, support for codependent fools *who* put up with our shit.
- Our search strategy: *Within the function analyze_wh_word we ...* We then check whether our item is one of ["who", "whom", "whose", "which"]. If yes, we first exclude all instances of sentence relatives, pied piping, and relative clauses in subject position. For all remaining cases we exclude structures that have a form of 'ask' or 'tell' as main verb and that do not have a noun preceding. We then count all structures that are followed by a verb or modal (with one potential intervening adverb) towards whresub_031.
```{python}
    if tagged_sentence[index-1][1].startswith("NN"):
        if tagged_sentence[index+1][1].startswith("RB"):
            if (tagged_sentence[index+2][1].startswith("V") or tagged_sentence[index+2][1].startswith("MD")):
                features_dict["thatresub_029"] += 1 
        elif tagged_sentence[index+1][1].startswith("VB") or tagged_sentence[index+1][1].startswith("MD"):
            features_dict["thatresub_029"] += 1
        elif tagged_sentence[index+1][1].startswith("DT") or tagged_sentence[index+1][1].startswith("JJ") or tagged_sentence[index+1][1] == "NNS" or tagged_sentence[index+1][1].startswith("NNP"):
            features_dict["thatreobj_030"] += 1
        elif tagged_sentence[index+1][0] == "it" or tagged_sentence[index+1][0] in subjpro or tagged_sentence[index+1][0] in posspro:
            features_dict["thatreobj_030"] += 1    
                
    else:
        if word_tuple[0] in WHP: # WHP = ["who", "whom", "whose", "which"]
            if tagged_sentence[index-1][1] == "IN":
                features_dict["whrepied_033"] += 1
            if word_tuple[0] == "which":
                if tagged_sentence[index-1][0] == ",": 
                    features_dict["sentencere_034"] += 1
                elif index == 3 and tagged_sentence[4][1].startswith("V"):
                    if not tagged_sentence[4][0] in belist:
                        features_dict["sentencere_034"] += 1

            #31. WH relative clauses on subject position (e.g., the man who likes popcorn) xxx + yyy + N + WHP + (ADV) + AUX/V 
            if tagged_sentence[index-1][1].startswith("N") and tagged_sentence[index-2][0] not in ["tell", "tells", "told", "telling", "ask", "asks", "asked", "asking"]:
                if tagged_sentence[index+1][1].startswith("R"):
                    if (tagged_sentence[index+2][1].startswith("V") or tagged_sentence[index+2][1].startswith("MD")):
                        features_dict["whresub_031"] += 1

                elif(tagged_sentence[index+1][1].startswith("V") or tagged_sentence[index+1][1].startswith("MD")):
                    features_dict["whresub_031"] += 1
        
```

- Accuracy:

## WH-relative clauses on object position: whreobj_032

- Definition from Biber: "xxx + yyy + N + WHP + zzz (where xxx is NOT any form of the verbs ASK or TELL, to exclude indirect WH questions, and zzz is not ADV, AUX or V, to exclude relativization on subject position)" (1988: 235)
- Example from Reddit: You didn't give any evidence and then proceeded to change your argument to something *which* I actually agree with.
- Our search strategy: *Within the function analyze_wh_word we ...* We then check whether our item is one of ["who", "whom", "whose", "which"]. If yes, we first exclude all instances of sentence relatives, pied piping, and relative clauses in subject position. For all remaining cases we exclude structures that have a form of 'ask' or 'tell' as main verb. We also exclude cases that have an adverb, verb, or modal following. All remaining structures are counted towards whreobj_032. 
```{python}
    if tagged_sentence[index-1][1].startswith("NN"):
        if tagged_sentence[index+1][1].startswith("RB"):
            if (tagged_sentence[index+2][1].startswith("V") or tagged_sentence[index+2][1].startswith("MD")):
                features_dict["thatresub_029"] += 1 
        elif tagged_sentence[index+1][1].startswith("VB") or tagged_sentence[index+1][1].startswith("MD"):
            features_dict["thatresub_029"] += 1
        elif tagged_sentence[index+1][1].startswith("DT") or tagged_sentence[index+1][1].startswith("JJ") or tagged_sentence[index+1][1] == "NNS" or tagged_sentence[index+1][1].startswith("NNP"):
            features_dict["thatreobj_030"] += 1
        elif tagged_sentence[index+1][0] == "it" or tagged_sentence[index+1][0] in subjpro or tagged_sentence[index+1][0] in posspro:
            features_dict["thatreobj_030"] += 1    
                
    else:
        if word_tuple[0] in WHP: # WHP = ["who", "whom", "whose", "which"]
            if tagged_sentence[index-1][1] == "IN":
                features_dict["whrepied_033"] += 1
            if word_tuple[0] == "which":
                if tagged_sentence[index-1][0] == ",": 
                    features_dict["sentencere_034"] += 1
                elif index == 3 and tagged_sentence[4][1].startswith("V"):
                    if not tagged_sentence[4][0] in belist:
                        features_dict["sentencere_034"] += 1

            #31. WH relative clauses on subject position (e.g., the man who likes popcorn) xxx + yyy + N + WHP + (ADV) + AUX/V 
            if tagged_sentence[index-1][1].startswith("N") and tagged_sentence[index-2][0] not in ["tell", "tells", "told", "telling", "ask", "asks", "asked", "asking"]:
                if tagged_sentence[index+1][1].startswith("R"):
                    if (tagged_sentence[index+2][1].startswith("V") or tagged_sentence[index+2][1].startswith("MD")):
                        features_dict["whresub_031"] += 1

                elif(tagged_sentence[index+1][1].startswith("V") or tagged_sentence[index+1][1].startswith("MD")):
                    features_dict["whresub_031"] += 1
        
            #32. WH relative clauses on object positions
            if not tagged_sentence[index-3][0].startswith("ask") and not tagged_sentence[index-3][0].startswith("tell") and not tagged_sentence[index-3][0] == "told": 
                if not tagged_sentence[index+1][1].startswith("R") and not tagged_sentence[index+1][1].startswith("V") and not tagged_sentence[index+1][1].startswith("MD"):
                    if tagged_sentence[index-1][1].startswith("N"):
                        features_dict["whreobj_032"] += 1 
```

- Accuracy: F-score of 

## Pied-piping relative clauses: whrepied_033

- Definition from Biber: "PREP + WHP" (1988: 235)
- Example from Reddit: Example from Biber: "the manner *in which* he was told" (Biber 1988: 235)
- Our search strategy: Within the function analyze_wh_word we first exclude all structures that follow a noun. In the remaining structures we check whether the item is part of ["who", "whom", "whose", "which"], and whether the preceding item is tagged as "IN" (Preposition or subordinating conjunction). If yes then the structure is counted as pied-piping. We therefore don't deviate from Biber's strategy. 
```{python}
    if tagged_sentence[index-1][1].startswith("NN"):
                
    else:
        if word_tuple[0] in WHP:
            if tagged_sentence[index-1][1] == "IN":
                features_dict["whrepied_033"] += 1 
```

- Accuracy: F-score of 

## Sentence relatives: sentencere_034

- Definition from Biber: "T#/, + which (These forms are edited by hand to exclude non-restrictive relative clauses.)" (1988: 235)
- Example from Reddit: *Which* is why we will be sending our military forces their way.
- Our search strategy: Within the function analyze_wh_word we first exclude all structures that follow a noun. We then check whether the item is part of ["who", "whom", "whose", "which"]. Next we exlude all structures that follow a preposition (which are pied-piping). We then narrow it down further to only items which are "which". These are counted either if they follow a comma or if they are in sentence-initial position and the next items is a verb (except be). We are therefore adding more conditions than Biber since we cannot afford manual analysis.
```{python}
    if tagged_sentence[index-1][1].startswith("NN"):
          
    else:
        if word_tuple[0] in WHP:
            if tagged_sentence[index-1][1] == "IN":
                features_dict["whrepied_033"] += 1

            if word_tuple[0] == "which":
                if tagged_sentence[index-1][0] == ",":
                    features_dict["sentencere_034"] += 1
                elif index == 3 and tagged_sentence[4][1].startswith("V"):
                    if not tagged_sentence[4][0] in belist:
                        features_dict["sentencere_034"] += 1
```

- Accuracy: F-score of 0.71

## Causative adverbial subordinators: advsubcause_035

- Definition from Biber: not stated, presumably surface form "because" (1988: 236)
- Example from Reddit: *Because* the Canucks gave the Flames the best offer.
- Our search strategy: Within the function analyze_preposition we check whether the item is "because" (or one of its spelling variants). We count all hits except the ones that are followed by "of". 
```{python}
    if word_tuple[0] in ["because", "becuase", "beacuse", "cause", "'cause", "cos", "'cos", "coz", "'coz", "caus", "'caus", "cuz", "'cuz", "bcoz", "bcuz", "bcos", "bcause", "bcaus"] and tagged_sentence[index+1][0] != "of":
        features_dict["advsubcause_035"] += 1 
        # AB: I decided against a separate feature for "because of" since it goes into "prepositions_039".
        # HM: I don't understand what this means. Biber (1988: 236-237) does not list "because of" as a preposition (even though it is an obvious contender),
        #     and it is purposefully excluded in the list above for "prepositions_039". Right now we are not counting "because of" at all, are we?
```

- Accuracy: F-score of 0.89

## Concessive adverbial subordinators: advsubconc_036

- Definition from Biber: not stated, presumably surface forms "although" or "though" (1988: 236)
- Example from Reddit: The parka copes fine with the rain, *although* I haven't been caught in any thunderstorms yet!
- Our search strategy: Within the function analyze_preposition we count all items with the surface form "although", "though" and "tho". We therefore deviate from Biber in including 'tho' and in checking for the word class preposition first.
```{python}
    elif word_tuple[0] == "although" or word_tuple[0] == "though" or word_tuple[0] == "tho":
        features_dict["advsubconc_036"] += 1 
```

- Accuracy: F-score of 0.80

## Conditional adverbial subordinators: advsubcond_037

- Definition from Biber: not stated, presumably surface forms "if" or "unless" (1988: 236)
- Example from Reddit: *If* Redskins get Williams...where is he playing?
- Our search strategy: Within the function analyze_sentence we are checking for "if" and "unless" either in sentence-medial or sentence-initial position.
```{python}
    for advsubcond in [" if ", " unless ", " if, ", " unless, "]:
        features_dict["advsubcond_037"] += sentence.count(advsubcond)
    if sentence.startswith("if ") or sentence.startswith("if, ") or sentence.startswith("unless ") or sentence.startswith("unless, "):
        features_dict["advsubcond_037"] += 1
```

- Accuracy: F-score of 1.00

## Other adverbial subordinators: advsubother_038

- Definition from Biber: "since, while, whilst, whereupon, whereas, whereby, such that, so that xxx, such that xxx, inasmuch as, forasmuch as, insofar as, insomuch as, as long as, as soon as (where xxx is NOT: N/ADJ)" (1988: 236)
- Example from Reddit: Just *as long as* you have a good time and enjoy your week here, you can't let anyone down!
- Our search strategy: Within the function analyze_preposition we check for all the single-word items that are part of Biber's list, they are included in the list "oteradvsublist". We also count all cases where the item itself is "that" and the preceding item is "such" or "so", to catch "such that" and "so that". All other items listed by Biber are searched via the analyze_sentence function (so using the untagged string of characters). Here we check for all surface forms. The only exceptions are "as long as" and "as soon as", which are counted only in sentence-initial position (to avoid uses in which the second item is a true adjective, e.g. "the key was as long as a pencil")
```{python}
otheradvsublist = ["since", "while", "whilst", "whereupon", "whereas", "whereby"]

## within the function analyze_preposition

    elif word_tuple[0] == "that" and tagged_sentence[index-1][0] in ["such", "so"]:
        features_dict["advsubother_038"] += 1 

    if word_tuple[0] in otheradvsublist:
        features_dict["advsubother_038"] += 1 

## within the function analyze_sentence

    for advsub in ["inasmuch as", "forasmuch as", "insofar as", "insomuch as", " as long as ", " as soon as "]:
        features_dict["advsubother_038"] += sentence.count(advsub)
    if sentence.startswith("as long as ") or sentence.startswith("as soon as "):
        features_dict["advsubother_038"] += 1
```

- Accuracy:

## Prepositions: prepositions_039

- Definition from Biber: "against, amid, amidst, among, amongst, at, besides, between, by, despite, during, except, for, from, in, into, minus, notwithstanding, of, off, on, onto, opposite, out, per, plus, pro, re, than, through, throughout, thru, to, toward, towards, upon, versus, via, with, within, without" (1988: 236-237)
- Example from Reddit: I clap *during* the Friends theme song.
- Our search strategy: Within the function analyze_preposition we are counting all items that are not one of ["because", "unless", "whilst", "while", "though", "tho", "although", "that", "since", "whereupon", "whereas", "whereby"] (because these are often or always conjunctins) and that are not parts of our list of adverbs of time and place. We therefore deviate significantly from Biber's procedure, as he looks for a finite list of items that he considers to be preposition. Again we rely more on our parts-of-speech tagger.
```{python}
    if not word_tuple[0] in ["because", "unless", "whilst", "while", "though", "tho", "although", "that", "since", "whereupon", "whereas", "whereby"] + timepoints + timedurfreq + placelist: 
        features_dict["prepositions_039"] += 1 
```

- Accuracy: F-score of 0.87

## Attributive adjectives: adjattr_040

- Definition from Biber: "ADJ + ADJ/N (+ any ADJ not identified as predicative - no. 41)" (1988: 238)
- Example from Reddit: All the documentaries I've seen, like FRONTLINE, paint Trump in a very *different* light.
- Our search strategy: Within the function analzye_adjective we set all adjectives to predicative as the default. We then look at the following items and only change the value to attributive if it is followed by a string of nouns or a string of adjectives + noun (which can also be separated by a come). We then count all structures that  have the value attributive
  We also tried this the other way around (starting with attributive as the default), but the results were less accurate.
```{python}
    adj_type = "pred"
    forward = 1
    while tagged_sentence[index+forward][1].startswith(("N","J")) or tagged_sentence[index+forward][0] == ",":
        if tagged_sentence[index+forward][1].startswith("N"):
            adj_type = "attr"
        forward += 1
    if adj_type == "attr":
        features_dict["adjattr_040b"] += 1
    elif adj_type == "pred":
        features_dict["adjpred_041b"] += 1
```

- Accuracy: F-score of 0.91

## Predicative adjectives: adjpred_041

- Definition from Biber: 
  "(a) BE + ADJ + xxx (where xxx is NOT ADJ, ADV, or N) 
  (b) BE + ADJ + ADV + xxx (where xxx is NOT ADJ or N)" (1988: 238)
- Example from Reddit: Updating the getmonero.org site would be *awesome*!
- Our search strategy: Within the function analzye_adjective we set all adjectives to predicative as the default. We then look at the following items and only change the value to attributive if it is followed by a string of nouns or a string of adjectives + noun (which can also be separated by a come). We then count all structures that still have the value predicative.
  We also tried this the other way around (starting with attributive as the default), but the results were less accurate.
```{python}
    adj_type = "pred"
    forward = 1
    while tagged_sentence[index+forward][1].startswith(("N","J")) or tagged_sentence[index+forward][0] == ",":
        if tagged_sentence[index+forward][1].startswith("N"):
            adj_type = "attr"
        forward += 1
    if adj_type == "attr":
        features_dict["adjattr_040b"] += 1
    elif adj_type == "pred":
        features_dict["adjpred_041b"] += 1
```

- Accuracy: F-score of 0.75

## Adverbs: adverbs_042

- Definition from Biber: "Any adverb form occurring in the dictionary, or any form that is longer than five letters and ends in -ly. The count for total adverbs excludes those adverbs counted as instances of hedges, amplifiers, downtoners, amplifiers, place adverbials, and time adverbials." (1988: 238)
- Example from Reddit: Let it *never* be said that I am an impatient man.
- Our search strategy: Within the function analyze_adverb we count all items that are caught by this function, so all items that receive the tag "RB" (advber), "RBR" (adverb, comparative), or "RBS" (adverb, superlative). This is a deviation from Biber, since we are not excluding the words covered by other features, and we are not checking for items in a dictionary (+ items longer than five letters ending in -ly), because we trust the accuracy of our parts-of-speech tagger.
```{python}
    features_dict["adverbs_042"] += 1
```

- Accuracy:

## Type-token ratio: ttratio_043

- Definition from Biber: "This feature is computed by counting the number of different lexical items that occur in the first 400 words of each text, and then dividing by four; texts shorter than 400 words are not included in the present analysis." (1988: 238-239)
- Our search strategy:
  *apparently not in our script?*
```{python}

```

- Accuracy: this was not coded manually and therefore not checked for accuracy.

## Word length: wordlength_044

- Definition from Biber: "mean length of the words in a text, in orthographic letters" (1988: 239)
- Our search strategy: Within the function analyze_sentence we count the length of all words in characters and divide it by the number of words in the sentence. *We deviate from Biber in that we replace ... with ... beforehand.*
```{python}
    words = sent.split()

    sum_wordlen = 0
    for word in words:
        word = re.sub(r'[^\w\s]','', word)
        wordlen = len(word)
        sum_wordlen = sum_wordlen + wordlen
    features_dict["wordlength_044"] = (sum_wordlen/len(words)) 
```

- Accuracy:  this was not coded manually and therefore not checked for accuracy.

## Conjuncts: conjuncts_045

- Definition from Biber: 
  "alternatively, altogether, consequently, conversely, eg, e.g., else, furthermore, hence, however, i.e., instead, likewise, moreover, namely, nevertheless, nonetheless, notwithstanding, otherwise, rather, similarly, therefore, thus, viz. 
  in + comparison/contrast /particular /addition /conclusion /consequence /sum /summary/ any event/ any case/ other words 
  for + example /instance 
  by + contrast / comparison 
  as a + result/consequence 
  on the + contrary/other hand 
  ALL-P/T# + that is/else / altogether+ T#, 
  ALL-P/T# + rather + T#/,/xxx (where xxx is NOT: ADJ/ADV)" (1988: 239)
- Example from Reddit: *However*, I would be happy if the race for President was between those two.
- Our search strategy: All of the one-word items listed by Biber that do not have punctuation attached to them are searched for within the analyze_adverb function. We count all items that have a surface form which is part of the list "conjunctslist", which we defined beforehand. The items in the list are the same as listed by Biber. The two-word items and the words with punctuation are searched for within the analyze_sentence function (so using the untagged string of characters forming the sentence).
```{python}
conjunctslist = ["alternatively", "altogether", "consequently", "conversely", "eg", "e.g.", "else", "furthermore",
                 "hence", "however", "ie", "i.e.", "instead", "likewise", "moreover", "namely", "nevertheless",
                 "nonetheless", "notwithstanding", "otherwise", "rather", "similarly", "therefore", "thus", "viz"]

## within the function analyze_adverb

    elif word_tuple[0] in conjunctslist:
        features_dict["conjuncts_045"] += 1

## within the function analyze_sentence

    for conjunct in ["on the contrary", "on the other hand", "for example", "for instance", "by contrast", "by comparison", "in comparison", "in contrast", "in particular", "in addition", "in conclusion", "in consequence", "in sum", "in summary", "in any event", "in any case", "in other words", "as a result", "as a consequence"]:
        features_dict["conjuncts_045"] += sentence.count(conjunct)
        
    for conjunct in ["that is,", "else,", "altogether,", "rather,"]:
        if sentence.startswith(conjunct):
            features_dict["conjuncts_045"] += 1
```

- Accuracy: F-score of 0.82

## Downtoners: downtoners_046

- Definition from Biber: "almost, barely, hardly, merely, mildly, nearly, only, partially, partly, practically, scarcely, slightly, somewhat" (1988: 240)
- Example from Reddit: Cheap individual health insurance fills that need nicely; it's *hardly* worthless.
- Our search strategy: Within the function analyze_adverb we are counting all items that are part of the list "downtonerlist". This list was defined beforehand and contains all the items mentioned by Biber.
```{python}
downtonerlist = ["almost", "barely", "hardly", "merely", "mildly", "nearly", "only", "partially", "partly", "practically", "scarcely", "slightly", "somewhat"]

    elif word_tuple[0] in downtonerlist:
        features_dict["downtoners_046"] += 1
```

- Accuracy: F-score of 0.82

## Hedges: hedges_047

- Definition from Biber: "at about /something like/more or less /almost/ maybe/xxx sort of/xxx kind of (where xxx is NOT: DET/ADJ/POSSPRO/WHO - excludes sort and kind as true nouns)" (1988: 240)
- Example from Reddit: *Maybe* they're the "one in a million"?
- Our search strategy: The structures within this feature are quite different in their composition, so we look for them in two different functions. 
  - Within the function analyze_prepositions we first check whether the surface form is "of" and the preceding item is either "kind" or sort" and the item before that is tagged as one of ["JJ", "JJR", "JJS", "DT", "PRP$"]. If this is the case we exclude all structures in which the word two to the left is ["what", "whatever", "whichever"] and count all remaining hits.
  - Within the function analyze_sentence (which has the untagged version of the entire sentence as input) we count the following strings of characters: [" at about ", " something like ", " more or less", " kinda ", " sorta ", " almost ", " maybe "]
  We are therefore deviating from Biber in also including the more colloquial forms "kinda" and "sorta". For "kind of" and "sort of" we also do not use the exact same conditions as Biber.
```{python}
## within analyze_preposition

    elif word_tuple[0] == "of" and tagged_sentence[index-1][0] in ["kind", "sort"] and not tagged_sentence[index-2][1] in ["JJ", "JJR", "JJS", "DT", "PRP$"]:
        if not tagged_sentence[index-2][0] in ["what", "whatever", "whichever"]:
            features_dict["hedges_047"] += 1
            
## within analyze_sentence

    for hedge in [" at about ", " something like ", " more or less", " kinda ", " sorta ", " almost ", " maybe "]:
        features_dict["hedges_047"] += sentence.count(hedge)
```

- Accuracy: F-score of 0.70

## Amplifiers and emphatics: amplifiers_048

- Definition from Biber for amplifiers: "absolutely, altogether, completely, enormously, entirely, extremely, fully, greatly, highly, intensely, perfectly, strongly, thoroughly, totally, utterly, very" (1988: 240)
- Definition from Biber for emphatics: "for sure/a lot/such a/real + ADJ /so + ADJ /DO + V / just/really /most /more" (1988: 241)
- Example from Reddit: *Extremely* so.
- Our search strategy: We are combining two features from Biber here because the theoretical delimitation is not clear to us. Within the function analyze_adverb we are couting all items that have a surface form listed in the list "amplifierlist". The list "amplifierlist" is defined beforhand and contains all the words mentioned by Biber plus our addition 'definitely'. From the original feature "emphatics" we are only keeping "for sure" because the other items strike us as ambiguous and not always emphatic in nature. We look for 'for sure' with in the function analyze_sentence (where we are only checking the untagged string of characters).
```{python}
amplifierlist = ["absolutely", "altogether", "completely", "definitely", "enormously", "entirely", "extremely", "fully", "greatly", "highly", "intensely", "perfectly", "strongly", "thoroughly", "totally", "utterly", "very"]

## within the function analyze_adverb:

    elif word_tuple[0] in amplifierlist:
        features_dict["amplifiers_048"] += 1 

## within the function analyze_sentence

    for emphatic in [" for sure"]: 
        features_dict["amplifiers_048"] += sentence.count(emphatic)
    if sentence.startswith("for sure"): # AB: Catch cases of sentence-initial "for sure" that have been excluded through the insertion of spaces above
        features_dict["amplifiers_048"] += 1
```

- Accuracy: F-score of 0.92

## Discourse particles: discpart_050

- Definition from Biber: "CL-P/T# + well/now/anyway/anyhow/anyways" (1988: 241)
- Example from Reddit: *Well*, not everyone is insecure about it.
- Our search strategy: Within the function analyze_particle we are counting all items that are part of the list "discpart", which is defined beforehand, and that are in sentence-initial position. The list "discpart" contains all items from Biber plus "though". We do the same in the analyze_adverb function just in case one of the discourse particles is tagged as an adverb.
```{python}
discpart = ["well", "now", "anyway", "anyhow", "anyways", "though"]

## within the function analyze_particle
    word_tuple = tagged_sentence[index]
    if index == 3 and word_tuple[0] in discpart: # index == 3 is the first actual element in the sentence, after the three ("x", "x") tuples
        features_dict["discpart_050"] += 1
    else:
        pass
      
## within the function analyze_adverb
    if index == 3 and word_tuple[0] in discpart: # index == 3 is the first actual element in the sentence, after the three ("x", "x") tuples
        features_dict["discpart_050"] += 1
```

- Accuracy:  F-score of 0.84

## Demonstratives: demonstr_051

- Definition from Biber: "that/this/these/those (This count excludes demonstrative pronouns (no. 10) and that as relative, complementizer, or subordinator.)" (1988: 241)
- Example from Reddit: *This* article is being considered for deletion ...
- Our search strategy: Within the function analyze_pronoun and within the function analyze_determiner we first check whether the surface form is 'that' or one of ["this", "these", "those"]. In the latter case we count the item as a demonstrative if it is followed by a noun or an adjective + noun. Other cases are considered demonstrative pronouns. If the item is 'that' we also count it if it is followed by a noun or an adjective + noun. We are implementing this procedure in both POS-functions because the POS-identification of the words in question is not always reliable.
```{python}
## within the function analyze_pronoun and within the function analyze_determiner

    if word_tuple[0] in ["this", "these", "those"]:
        if tagged_sentence[index+1][1].startswith("NN"):
            features_dict["demonstr_051"] += 1
        elif tagged_sentence[index+1][1].startswith("JJ") and tagged_sentence[index+2][1].startswith("NN"):
            features_dict["demonstr_051"] += 1
        else:
            features_dict["prodemons_010"] += 1
            
    if word_tuple [0] == "that":
        if tagged_sentence[index+1][1].startswith("NN"):
            features_dict["demonstr_051"] += 1
        elif tagged_sentence[index+1][1].startswith("JJ") and tagged_sentence[index+2][1].startswith("NN"):
            features_dict["demonstr_051"] += 1
        elif tagged_sentence[index+1][0] == "X":
            features_dict["prodemons_010"] += 1
        elif tagged_sentence[index+1][1].startswith("JJ"):
            features_dict["prodemons_010"] += 0
        else:
            features_dict["prodemons_010"] += 1
```

- Accuracy: F-score of 0.94

## Possibility modals: modalsposs_052

- Definition from Biber: "can/may/might/could (+ contractions)" (1988: 241)
- Example from Reddit: You *can* change these things for the Internet Explorer COM component too.
- Our search strategy: Within the function analyze_modal we are counting all items with the surface forms ["can","may","might","could"]. We are not considering any contractions.
```{python}
    word_tuple = tagged_sentence[index]
    if word_tuple[0] in ["can","may","might","could"]:
        features_dict["modalsposs_052"] += 1
```

- Accuracy:  F-score of 0.90

## Necessity modals: modalsness_053

- Definition from Biber: "ought/should/must (+ contractions)" (1988: 242)
- Example from Reddit: They *should* be shot dead with cheap bullets.
- Our search strategy: Within the function analyze_modal we count everything with the surface form ["ought","should","must"]. We are not considering any contractions.
```{python}
    elif word_tuple[0] in ["ought","should","must"]:
        features_dict["modalsness_053"] += 1
```

- Accuracy:  F-score of 0.82

## Predictive modals: modalspred_054

- Definition from Biber: "will/would/shall ( + contractions)" (1988: 242)
- Example from Reddit: He's also literally Space Jesus so I *would*n't worry about it.
- Our search strategy: Within the function analyze_model we are couting everything with the surface form ["will","would","shall","'ll","'d"]. 
```{python}
    elif word_tuple[0] in ["will","would","shall","'ll","'d"]: 
        features_dict["modalspred_054"] += 1
```

- Accuracy: F-score of 0.95

## Public verbs: vpublic_055

- Definition from Biber: "(e.g., acknowledge, admit, agree, assert, claim, complain, declare, deny, explain, hint, insist, mention, proclaim, promise, protest, remark, reply, report, say, suggest, swear, write)" (1988: 242)
- Example from Reddit: It's worth pointing out that in America you can no longer *say* that everyone has a right to a fair trial.
- Our search strategy: Within the function analyze_verb we count everything that is part of the list "publiclist". This list was defined beforehand and contains all the lemmata mentioned by Biber as well as their inflected forms (since we are checking for surface forms).
```{python}
publiclist = ["acknowledege", "acknowledges", "acknowledged", "acknowledging", "admit", "admits", "admitted", "admitting",
              "agree", "agrees", "agreed", "agreeing", "assert", "asserts", "asserted", "asserting", "claim", "claimed", 
              "claims", "claiming", "complain", "complains", "complained", "complaining", "declare", "declared", "declares",
              "declaring", "deny", "denies", "denied", "denying", "explain", "explains", "explained", "explaining", "hint",
              "hints", "hinted", "hinting", "insist", "insisted", "insists", "insisting", "mention", "mentions", "mentioned",
              "mentioning", "proclaim", "proclaims", "proclaimed", "proclaiming", "promise", "promises", "promised", "promising",
              "protest", "protests","protested", "protesting", "remark", "remarks", "remarking", "remarked", "reply", 
              "replied", "replies", "replying", "report", "reports", "reported", "reporting", "say", "says", "said", "saying",
              "suggest", "suggests", "suggested", "suggesting", "swear", "swears", "swore", "swearing", "write", "wrote", "writing", "writes"]

    if word_tuple[0] in publiclist:
        features_dict["vpublic_055"] += 1
```

- Accuracy: F-score of 0.95

## Private verbs: vprivate_056

- Definition from Biber: "(e.g., anticipate, assume, believe, conclude, decide, demonstrate, determine, discover, doubt, estimate, fear, feel, find, forget, guess, hear, hope, imagine, imply, indicate, infer, know, learn, mean, notice, prove, realize, recognize, remember, reveal, see, show, suppose, think, understand)" (1988: 242)
- Example from Reddit: Yeah, I do *remember* reading about it.
- Our search strategy: Within the function analyze_verb we count everything that is part of the list "privatelist". This list was defined beforehand and contains all the lemmata mentioned by Biber as well as their inflected forms (since we are checking for surface forms).
```{python}
privatelist = ["anticipate", "anticipates", "anticipated", "anticipating", "assume", "assumes", "assumed", "assuming",
               "believe", "believes", "believed", "believing", "conclude", "concludes", "concluded", "concluding", "decide",
               "decides", "decided", "deciding", "demonstrate", "demostrates", "demonstrated","demonstrating", "determine",
               "determines", "determined", "determining", "discover", "discovers", "discovered", "discovering", "doubt",
               "doubts", "doubted", "doubting", "estimate", "estimated", "estimates", "estimating", "fear", "fears", "feared",
               "fearing", "feel", "feels", "feeled", "feeling", "find", "finds", "found", "finding", "forget", "forgets", 
               "forgot", "forgetting", "guess", "guesses", "guessed", "guessing", "hear", "hears", "heard", "hearing", "hope",
               "hopes", "hoped", "hoping", "imagine", "imagines", "imagined", "imagining", "imply", "implies", "implied", 
               "implying", "indicate", "indicates", "indicating", "indicated", "infer", "infers", "infered", "inferring", "inferred",
               "know", "knows", "knew", "knowing", "learn", "learns", "learnt", "learned", "learning", "mean", "means", "meant",
               "meaning", "notice", "notices", "noticed", "noticing", "prove", "proves", "proved", "proving", "realise", "realize",
               "realised", "realized", "realises","realizes", "realising", "realizing", "recognise", "recognize", "recognises",
               "recognizes", "recognised", "recognized", "recognising", "recognizing", "remember", "remembers", "remembered",
               "remembering", "reveal", "reveals", "revealing", "revealed", "see", "sees", "saw", "seen", "seeing", "show", "shows",
               "showed", "showing", "suppose", "supposed", "supposes", "supposing", "think", "thinks", "thought", "thinking",
               "understand", "understands", "understood", "understanding"]

    if word_tuple[0] in privatelist:
        features_dict["vprivate_056"] += 1
```

- Accuracy: F-score of 0.93

## Suasive verbs: vsuasive_057

- Definition from Biber: "(e.g., agree, arrange, ask, beg, command, decide, demand, grant, insist, instruct, ordain, pledge, pronounce, propose, recommend, request, stipulate, suggest, urge)" (1988: 242)
- Example from Reddit: His forehead makes me want to *ask* him if he needs help with a quest.
- Our search strategy: Within the function analyze_verb we count everything that is part of the list "suasivelist". This list was defined beforehand and contains all the lemmata mentioned by Biber as well as their inflected forms (since we are checking for surface forms).
```{python}
suasivelist = ["agree", "agrees", "agreed", "agreeing", "arrange", "arranges", "arranged", "arranging", "ask", "asks", "asked",
               "asking", "beg", "begs", "begged", "begging", "command", "commands", "commanded", "commanding", "decide", "decides",
               "decided", "deciding", "demand", "demands", "demanding", "demanded", "grant", "grants", "granted", "granting",
               "insist", "insists", "insisted", "insisting", "instruct", "instructs", "instructed", "instructing", "ordain", 
               "ordains", "ordained", "ordaining", "pledge", "pledges", "pledging", "pledged", "pronounce", "pronounces", 
               "pronounced", "pronouncing", "propose", "proposes", "proposed", "proposing", "recommend", "recommends", "recommended",
               "recommending", "request", "requests", "requested", "requesting", "stipulate", "stipulates", "stipulated", "stipulating",
               "suggest", "suggests", "suggested", "suggesting", "urge", "urged", "urges", "urging"]

    if word_tuple[0] in suasivelist:
        features_dict["vsuasive_057"] += 1
```

- Accuracy:  F-score of 0.95

## Seem and appear: vseemappear_058

- Definition from Biber: not stated, presumable surface forms "seem" and "appear" (1988: 242)
- Example from Reddit: That *seems* like a weird place to draw the line, of course logic has no place in religion.
- Our search strategy: Within the function analyze_verb we are counting all items that start with "seem" or "appear".
```{python}
    if word_tuple[0].startswith("seem") or word_tuple[0].startswith("appear"):
        features_dict["vseemappear_058"] += 1
```

- Accuracy: F-score of 1.00

## Contractions: contractions_059

- Definition from Biber: 
  "(1) all contractions on pronouns
  (2) all contractions on auxiliary forms (negation) 
  (3) 's suffixed on nouns is analyzed separately (to exclude possessive forms): N's + V/AUX/ADV+V/ADV+AUX/DET/POSSPRO/PREP/ADJ+CL-P/ADJ+T#" (1988: 243)
- Example from Reddit: If the building were about to collapse, they would*n't* have a conference about it, they would leave the building.
- Our search strategy: Within the function analyze_verb we count all items that start with an apostrophe. Within the function analyze_modal we also count all items that start with an apostrophe. Within the function analyze_adverb we cound all items with the surface form "n't". This is a deviation from Biber in that we don't identify contractions based on the word class of the host, but we search for the clitics themselves.
```{python}
## within the function analyze_verb

    if word_tuple[0].startswith("'"):
        features_dict["contractions_059"] += 1
        
## within the function analyze_modal

    if word_tuple[0].startswith("'"):
        features_dict["contractions_059"] += 1
        
## within the function analyze_adverb

    if word_tuple[0] == "n't":
        features_dict["negana_067"] += 1
        features_dict["contractions_059"] += 1

```

- Accuracy: F-score of 0.95

## Stranded prepositions: strandprep_061

- Definition from Biber: "PREP + ALL-P/T#" (1988: 244)
- Example from Reddit: Gleeson, Issac, Serkis, and the old crew are the actors I have the most faith *in*.
- Our search strategy: Within the function analyze_preposition we first check whether this is the sentence-final item. If yes, we exclude everything that is "that" or "like" and count all remaining items towards the function. This is a slight deviation from Biber, he only checks for sentence-final position. We decided to exclude 'that' and 'like' because of cases like "More like: ..." and because of the multifunctionality of 'that' in general.
```{python}
    if tagged_sentence[index+1][0] in ALLP or tagged_sentence[index+1][1] == "X":
        if tagged_sentence[index+1][1] not in ["that", "like"]: 
            features_dict["strandprep_061"] += 1
```

- Accuracy: F-score of 0.69

## Split infinitives: vsplitinf_062

- Definition from Biber: "to + ADV + (ADV) + VB" (1988: 244)
- Example from Reddit: That's true, but it's much harder *to automatically detect*.
- Our search strategy: Within the function analyze_verb we are first checking for the tag "VB" (Verb, base form) and eliminating any instances that are sentence-initial or after a comma. We are counting the structure as a split infinitive if the item two slots before is "to", the previous item is tagged as RB (adverb), and the previous item is not "not" or "n't". We are also allowing for one additional intervening adverb between "to" and the verb itself, just like Biber does.
```{python}
    elif word_tuple[1] == "VB":
        if tagged_sentence[index-1][1] == "X" or tagged_sentence[index-1][0] == ",": 
            features_dict["vimperative_205"] += 1
        else: 
            features_dict["vinfinitive_024"] += 1
            if tagged_sentence[index-2][0] == "to":
                if tagged_sentence[index-1][1] == "RB" and not tagged_sentence[index-1][0] in ["n't", "not"]:
                    features_dict["vsplitinf_062"] += 1
                else:
                    pass
            elif tagged_sentence[index-3][0] == "to":
                if tagged_sentence[index-2][1] == "RB" and not tagged_sentence[index-2][0] in ["n't", "not"]:
                    if tagged_sentence[index-1][1] == "RB" and not tagged_sentence[index-1][0] in ["n't", "not"]:
                        features_dict["vsplitinf_062"] += 1
                else:
                    pass
```

- Accuracy: F-score of 0.67

## Split auxiliaries: vsplitaux_063

- Definition from Biber: "AUX + ADV + (ADV) + VB" (1988: 244)
- Example from Reddit: A horse would notice stepping on someone and it *would probably move*.
- Our search strategy: We look for this features at several places in our code.
  Within the function analyze_verb:
  - split present participles: we select all verbs with the tag "VBG" (Verb, gerund or present participle). After sorting out all non-finite clauses, we count all structures in which the item one to the left is an adverb and the item two to the left is a form of 'be' ("I was hardly paying attention")
  - split past perfect: we select all verbs with the surface form "had" or "'d". If there is a word with the tag VBN (Verb, past participle) following, and an unspecified number of adverbs in between, we count it as a split auxiliary.
  - split present perfect: we select all verbs with the surface form "have", "'ve" or "has" (we are not including 's because of its multifunctionality). If there is a word with the tag VBN (Verb, past participle) following, and an unspecified number of adverbs in between, we count it as a split auxiliary.
  - split passives: we first select all items that are form of 'be'. We exclude uses as main verbs. If there is a word with the tag VBN (Verb, past participle) following, and an unspecified number of adverbs in between, we count it as a split auxiliary.
  - split do-support: we select all verbs that are a form of "do". If there is a word a verbal tag (starting with V) following, and an unspecified number of adverbs in between, we count it as a split auxiliary.
  Within the function analyze_modal: 
  - split modal verbs: we count all modals that have a verb (tag starts with V) following after an unspecified number of adverbs.
```{python}
## within the function analyze_verb

    elif word_tuple[1] == "VBG":
        if (tagged_sentence[index-1][1] == "X" or tagged_sentence[index-1][0] in ALLP):
            if tagged_sentence[index+1][1] in ["IN", "DT", "RB", "WP","PRP", "WRB"]:
                features_dict["vpresentpart_025"] += 1
        if (tagged_sentence[index-2][1] == "X" or tagged_sentence[index-2][0] in ALLP):
            if tagged_sentence[index-1][0] in ["while", "without", "when", "although","with"]:
                features_dict["vpresentpart_025"] += 1
        elif tagged_sentence[index-1][1] == "NN" or tagged_sentence[index-1][1] == "NNS": 
            features_dict["vpresentwhiz_028"] += 1 
        elif tagged_sentence[index-1][0] in belist:
            features_dict["vprogressive_217"] += 1
        elif (tagged_sentence[index-2][0] in belist) and (tagged_sentence[index-1][1] == "RB"):
            features_dict["vprogressive_217"] += 1  
            features_dict["vsplitaux_063"] += 1

    if word_tuple[0] in ["had", "'d"]: 
        move_on = True
        insert_adv = False
        x = index
        while move_on:
            x += 1
            if tagged_sentence[x][1] == "VBN":
                move_on = False
                features_dict["vpastperfect_002b"] += 1
                if insert_adv:
                    features_dict["vsplitaux_063"] += 1
            elif tagged_sentence[x][1].startswith("R") and tagged_sentence[x][0] not in ["n't", "not"]:
                insert_adv = True
            elif tagged_sentence[x][1].startswith("N") or tagged_sentence[x][1].startswith("P"):
                move_on = True 
            else: 
                move_on =  False 

    elif word_tuple[0] in ["have", "'ve", "has"]: 
        move_on = True
        insert_adv = False
        x = index
        while move_on: 
            x += 1
            if tagged_sentence[x][1] == "VBN":
                move_on = False
                features_dict["vpresperfect_002a"] += 1
                if insert_adv:
                    features_dict["vsplitaux_063"] += 1
            elif tagged_sentence[x][1].startswith("R") and tagged_sentence[x][0] not in ["n't", "not"]:
                insert_adv = True
            elif tagged_sentence[x][1].startswith("N") or tagged_sentence[x][1].startswith("P"): 
                move_on = True
            else: 
                move_on = False

    elif word_tuple[0] in belist:
        if tagged_sentence[index+1][1] in ["DT", "PRP$", "JJ", "JJR", "JJS", "NN", "NNS", "NNP"]:
            features_dict["mainvbe_019"] += 1
        elif tagged_sentence[index+1][1] == "RB" and tagged_sentence[index+2][1] in ["DT", "PRP$", "JJ", "JJR", "JJS", "NN", "NNS", "NNP"]:
            features_dict["mainvbe_019"] += 1
            
        else:
            move_on = True
            insert_adv = False
            x = index
            while move_on == True:
                x += 1
                if tagged_sentence[x][1] == "VBN":
                    move_on = False
                    if tagged_sentence[x+1][0] == "by":
                        features_dict["passby_018"] += 1
                        if insert_adv:
                            features_dict["vsplitaux_063"] += 1
                    elif tagged_sentence[x+1][1] == "IN": 
                        x += 1
                        move_on2 = True
                        while move_on2:
                            x += 1
                            if tagged_sentence[x+1][1].startswith("N") or tagged_sentence[x+1][1].startswith("DT"):
                                pass
                            elif tagged_sentence[x+1][0] == "by":
                                features_dict["passby_018"] += 1
                                if insert_adv:
                                    features_dict["vsplitaux_063"] += 1
                                move_on2 = False
                            else:
                                features_dict["passagentl_017"] += 1
                                if insert_adv:
                                    features_dict["vsplitaux_063"] += 1
                                move_on2 = False
                    else:
                        features_dict["passagentl_017"] += 1
                        if insert_adv:
                            features_dict["vsplitaux_063"] += 1  
                elif tagged_sentence[x][1].startswith("RB"):
                    if tagged_sentence[x][0] not in ["n't", "not"]:
                        insert_adv = True
                    else:
                        pass
                else:
                    move_on = False

    elif word_tuple[0] in dolist:
        move_on = True
        negator = False
        insert_adv = False
        x = index
        while move_on:
            x += 1
            if tagged_sentence[x][1].startswith("V"):
                move_on = False
                if negator == False:
                    features_dict["amplifiers_048"] += 1
                if insert_adv:
                    features_dict["vsplitaux_063"] += 1
            elif tagged_sentence[x][0] in ["not", "n't"]:
                negator = True
            elif tagged_sentence[x][1].startswith("R"):
                insert_adv = True
            else:
                move_on = False


## within the function analyze_modal

    move_on = True
    insert_adv = False
    x = index
    while move_on:
        x += 1
        if tagged_sentence[x][1].startswith("V"):
            move_on = False
            if insert_adv:
                features_dict["vsplitaux_063"] += 1
        elif tagged_sentence[x][0] in ["not", "n't"]:
            pass
        elif tagged_sentence[x][1].startswith("R"):
            insert_adv = True
        else:
            move_on = False
```

- Accuracy: F-score of 0.86

## Synthetic negation: negsyn_066

- Definition from Biber: 
    "(a) no + QUANT/ADJ/N 
    (b) neither, nor (excludes no as a response)" (1988: 245)
- Example from Reddit: More accurate would be "Where there is *no* freedom, poverty persists".
- Our search strategy: Within the function analyze_determiner we first count everything that has the surface form "neither" or "nor". We then check for the surface form "no" and only count these structures of they are followed by a noun (tag starting with "NN"), by an adjective (tag starting with "JJ") or by an item in the list QUAN. The list QUAN is the same as in Biber, we therefore don't deviate from his search strategy.
```{python}
QUAN = ["each", "all", "every", "many", "much", "few", "several", "some", "any"]

    if word_tuple[0] == "neither" or word_tuple[0] == "nor":
        features_dict["negsyn_066"] += 1
    elif word_tuple[0] == "no":
        if tagged_sentence[index+1][1].startswith("NN") or tagged_sentence[index+1][1].startswith("JJ"):
            features_dict["negsyn_066"] += 1
        elif tagged_sentence[index+1][0] in QUAN:
            features_dict["negsyn_066"] += 1
```

- Accuracy: F-score of 0.82

## Analytic negation: negana_067

- Definition from Biber: "not (also contracted forms)" (1988: 245)
- Example from Reddit: I tried to spam Q every time it's up on him and ca*n't* even get oom'd.
- Our search strategy: Within the function analyze_adverb we count everything with the surface form "not" or "n't". The only deviation from Biber is therefore that we are restricting the search to items that are tagged as adverbs. 
```{python}
    word_tuple = tagged_sentence[index]
    if word_tuple[0] == "not":
        features_dict["negana_067"] += 1
    if word_tuple[0] == "n't":
        features_dict["negana_067"] += 1
        features_dict["contractions_059"] += 1
```

- Accuracy: F-score of 0.93

## Hashtags: hashtag_201

- Definition from Clark & Grieve (2017): none given.
- Example from Reddit: *#BEST* FUCKING POST EVER
- Our search strategy: Within the function analyze_sentence (where we work with the untagged string of characters) we are counting all items that start with a # and that have alphanumerical characters following.
```{python}
    features_dict["hashtag_201"] = len(re.findall(r"#\w+", sentence))
```

- Accuracy: F-score of 1.00

## Reddit-internal links: link_202

- Definition from Clark & Grieve (2017): none given.
- Example from Reddit: *[What's Up](https://youtu.be/6NXnxTNIWkc)* by 4 Non Blondes
- Our search strategy: Within the function analyze_sentence (where we work with the untagged string of characters) we count all items that start with u/ (indicating a user name) or starting with r/ (indicating a subreddit).
```{python}
        if words[i].lower().startswith("u/"):
            features_dict["link_202"] += 1 
            words[i] = "username"
                
        if words[i].lower().startswith("r/"):
            features_dict["link_202"] += 1 
            words[i] = "subredditname"
```

- Accuracy:

## Reddit-external links: interlink_203

- Definition: Links to websites other than Reddit.
- Example from Reddit: *[Asymmetric Warfare](https://en.wikipedia.org/wiki/Asymmetric_warfare)*
- Our search strategy: Within the function analyze_sentence (where we work with the untagged string of characters) we count all items that start with "http" or with "www".
```{python}
        if "http" in words[i].lower() or "www" in words[i].lower():
            features_dict["interlink_203"] += 1 
            words[i] = "url"
```

- Accuracy:

## Words in all caps: caps_204

- Definition from Clark & Grieve (2017): none given.
- Example from Reddit: no, *YOU* make it, thats the point
- Our search strategy:
```{python}

```

- Accuracy:

## Verbs in the imperative: vimperative_205

- Definition from Clark & Grieve (2017): none given.
- Example from Reddit: *Save* the cross!
- Our search strategy: Within the function analyze_verb we count all items that received the tag "VB" (Verb, base form) and that are either at the beginning of a sentence or after a comma.
```{python}
    word_tuple = tagged_sentence[index]
    if word_tuple[1] == "VBD":
        features_dict["vpast_001"] += 1
    elif word_tuple[1] == "VB":
        if tagged_sentence[index-1][1] == "X" or tagged_sentence[index-1][0] == ",": 
            features_dict["vimperative_205"] += 1
```

- Accuracy: F-score of 0.64

## Strategic lengthening within words: lengthening_206

- Definition: Words in which an individual letter is repeated (3 instanes or more) for emphasis.
- Example from Reddit: "I've come here to chew some bubble gum and kick some ass......*aaand* I'm all out of bubble gum" 
- Our search strategy: Within the function analyze_sentence (which takes the raw string of characters as input) we apply the function lengthening() to each item and count it if the function returns 'true'. The function returns true if there are 3 or more identical characters in direct sequence within the word (excluding www).
```{python}
def lengthening(word):
    '''Takes a word as an argument. Returns True if any sequence of 3+
    identical characters is in the word, with the exception of multiple
    "w"s (to avoid false positives with websites). Else returns False.'''
    count = 1
    character = ""
    for c in word:
        if c == character and c.isalpha() and not c == "w":
            count += 1
            if count == 3:
                return(True)
        else:
            count = 1
            character = c
    return(False)

## within the function analyze_sentence:

    for i in range(len(words)):
        if lengthening(words[i].lower()):
            features_dict["lengthening_206"] += 1
```

- Accuracy: F-score of 0.93

## Emoticons: emoticons_207

- Definition: Combinations of punctuation marks to imitate a facial expression.
- Example from Reddit: Call that a typo... *:P*
- Our search strategy: Within the function analyze_sentence we count all combinations of punctuation marks that are commonly used to form emoticons.
```{python}
    for emoticon in [":-)", ":)", ";-)", ":-p", ";-p", ":-(", ";-(", ":-o", "^^", "-.-", ":-$", ":-\\", ":-/", ":-|", ";-/", ";-\\", ":-[", ":-]", ":-§", "owo", "*.*", ";)", ":p", ";p", ":(", ";(", ":o", ":|", ";/", ";\\", ":[", ":]", ":§", ":-d"]:
        features_dict["emoticons_207"] += sentence.count(emoticon)
```

- Accuracy: F-score of 0.89

## Qeustion sentences: question_208

- Definition: All sentences ending in a question mark.
- Example from Reddit: What about people with very common names (could happen a lot with Chinese people)*?*
- Our search strategy: Within the function analyze_sentence we count all sentences that end with the symbol ?
```{python}
    if sentence.endswith("?"):
        features_dict["question_208"] += 1
```

- Accuracy: F-score of 1.00

## Exclamation sentences: exclamation_209

- Definition: All sentences ending in an exclamation mark.
- Example from Reddit: crazy*!*
- Our search strategy: Within the function analyze_sentence we count all sentences that end with the symbol !
```{python}
    if sentence.endswith("!"):
        features_dict["exclamation_209"] += 1
```

- Accuracy: F-score of 1.00

## Sentence length in characters: lenchar_210

- Definition: Length of the sentence in characters (that includes symbols, numberals, and punctuation marks).
- Our search strategy: Within the function analyze_sentence we count the number of characters in the string.
```{python}
    features_dict["lenchar_210"] = len(sentence) 
```

- Accuracy: this was not manually coded and therefore also not checked for accuracy.

## Sentence length in words: lenword_211

- Definition: The number of orthographic units within a sentence.
- Our search strategy: Within the function analyse_sentence we split the string of characters at every whitespace and count the number of remaining units.
```{python}
    features_dict["lenword_211"] = len(sentence.split(" ")) 
```

- Accuracy: this was not manually coded and therefore also not checked for accuracy.

## Synthetic comparatives: comparatives_syn_212

- Definition from Clark & Grieve (2017): none given.
- Example from Reddit: raiders of the lost arc was much, much *worse*
- Our search strategy: Within the function analyze_adjective we count all items that received the tag JJR (Adjective, comparative).
```{python}
    if tagged_sentence[index][1] == "JJR":
        features_dict["comparatives_syn_212"] += 1
```

- Accuracy: F-score of 0.69

## Synthetic superlatives: superlatives_syn_213

- Definition from Clark & Grieve (2017): none given.
- Example from Reddit: Because the Canucks gave the Flames the *best* offer.
- Our search strategy: Within the function analyze_adjective we count all items with the tag JJS (Adjective, superlative)
```{python}
    elif tagged_sentence[index][1] == "JJS":
        features_dict["superlatives_syn_213"] += 1
```

- Accuracy: F-score of 0.77

## Analytic comparatives: comparatives_ana_214

- Definition from Clark & Grieve (2017): none given.
- Example from Reddit: *More accurate* would be "Where there is no freedom, poverty persists".
- Our search strategy: Within the function analyze_adjective we are counting all items that have the word "more" preceding them.
```{python}
    if tagged_sentence[index-1][0] == "more":
        features_dict["comparatives_ana_214"] += 1
```

- Accuracy: F-score of 0.75

## Analytic superlatives: superlatives_ana_215

- Definition from Clark & Grieve (2017): none given.
- Example from Reddit: *Most pathetic* quote of all time:
- Our search strategy: Within the function analyze_adjective we are counting all items that have the word "most" preceding them.
```{python}
    elif tagged_sentence[index-1][0] == "most":
        features_dict["superlatives_ana_215"] += 1
```

- Accuracy: F-score of 0.80

## Community-specific abbreviations or words: reddit_vocab_216

- Definition: Presence of abbreviations or lexical items that are frequently used on or specific to Reddit.
- Example from Reddit: Congrats Raj, you got me to *upvote* a pic *post*.
- Our search strategy: Within the function analyze_sentence we check for various surface forms that we identified as Reddit-specific vocabulary. Usage of these lexical items or abbreviations marks the author as an experiences Reddit user.
```{python}
    for i in range(len(words)):
        if lengthening(words[i].lower()):
            features_dict["lengthening_206"] += 1
        if words[i].lower() in ["op", "subreddit", "sub", "subreddits", "upvoted", "posted", "repost", "thread", "upvotes", "upvote", "upvoting", "reddit", "redditor", "redditors", "post", "posts", "mod", "mods", "flair", "karma", "downmod", "downmodding", "downvote", "downvoting", "modding"]:
            features_dict["reddit_vocab_216"] += 1 
```

- Accuracy: F-score of 0.84

## verbs in the progressive aspect: vprogressive_217

- Definition: finite progressive verb phrases (ing-form and form of BE)
- Example from Reddit: If Redskins get Williams...where is he *playing*?
- Our search strategy: Within the function analyze_verb we first check whether the word received the tag VBG (Verb, gerund or present participle). If yes, we first sort out sentence-initial instances and cases preceded by markers of non-finite adverbial clauses. We then sort out instances following nouns. If the word is preceded by a form of BE (listed in "belist") we count it for this feature. Also, if the word two to the left is a form of BE and the word to the left is an adverb (tag RB) we count it towards this feature.
```{python}
    elif word_tuple[1] == "VBG":
        if (tagged_sentence[index-1][1] == "X" or tagged_sentence[index-1][0] in ALLP):
            if tagged_sentence[index+1][1] in ["IN", "DT", "RB", "WP","PRP", "WRB"]:
                features_dict["vpresentpart_025"] += 1
        if (tagged_sentence[index-2][1] == "X" or tagged_sentence[index-2][0] in ALLP):
            if tagged_sentence[index-1][0] in ["while", "without", "when", "although","with"]:
                features_dict["vpresentpart_025"] += 1
        elif tagged_sentence[index-1][1] == "NN" or tagged_sentence[index-1][1] == "NNS": 
            features_dict["vpresentwhiz_028"] += 1 
        elif tagged_sentence[index-1][0] in belist:
            features_dict["vprogressive_217"] += 1
        elif (tagged_sentence[index-2][0] in belist) and (tagged_sentence[index-1][1] == "RB"):
            features_dict["vprogressive_217"] += 1  
            features_dict["vsplitaux_063"] += 1
```

- Accuracy: F-score of 0.80

## Emojis: emojis_218

- Definition:
- Our search strategy: Within the function analyze_sentence we ...
```{python}
    features_dict["emojis_218"] = adv.extract_emoji(sentence)["overview"]["num_emoji"]
```

- Accuracy: this was not coded manually and therefore also not checked for accuracy.


## Coordination with 'and': coordAnd_219

- This feature is not included in Biber (1988). We decided to add it because we found Biber's distinction of phrasal vs. non-phrasal coordination impossible to implement.
- Example from Reddit: If the people have something, they can use these tactics *and* others to wage a campaign.
- Our search strategy: Within the function "analyze_conjunction" we count all items with the surface form "and".
```{python}
    if word_tuple[0].lower() == "and": 
        features_dict["coordAnd_219"] += 1
```

- Accuracy: F-score of 1.00

## Coordination with 'but': coordBut_220

- This feature is not included in Biber (1988). We decided to add it because we found Biber's distinction of phrasal vs. non-phrasal coordination impossible to implement.
- Example from Reddit: It might be dropping, *but* it wont drop to what Striker orange fsl's are.
- Our search strategy: Within the function "analyze_conjunction" we count all items with the surface form "but".
```{python}
    elif word_tuple[0].lower() == "but": 
        features_dict["coordBut_220"] += 1
```

- Accuracy: F-score of 1.00

## Coordination with 'or': coordOr_221

- This feature is not included in Biber (1988). We decided to add it because we found Biber's distinction of phrasal vs. non-phrasal coordination impossible to implement.
- Example from Reddit: Was hoping a looking for teams sub *or* thread existed but couldn't find one.
- Our search strategy: Within the function "analyze_conjunction" we count all items with the surface form "ot".
```{python}
    elif word_tuple[0].lower() == "or": 
        features_dict["coordOr_221"] += 1
```

- Accuracy: F-score of 1.00


# Features that were discarded

The following features were initially coded but then removed from the script because we could not reach a satisfying level of accuracy.


## that-relative clauses on object position: thatreobj_030

- Definition from Biber: "N + (T#) + that + DET/SUBJPRO/POSSPRO/it/ADJ/plural noun/proper noun/possessive noun/TITLE (This algorithm does not distinguish between that complements to nouns and true relative clauses.)" (1988: 234)
- Example from Reddit: Can someone remind me what happened to the whole dad quest *that* Oliver was supposed to be on?
- Our search strategy: Within the function analyze_wh_word we first select only structures that have a noun preceding the wh-word. We then exclude structures that are followed by a verb or modal (with one potential intervening adverb). If the following item is a determiner or adjective or plural/mass noun we count it towards thatreobj_030. WE also count it if it is followed by the word 'it' or a subject pronoun or possessive pronoun.
```{python}
    if tagged_sentence[index-1][1].startswith("NN"):
        if tagged_sentence[index+1][1].startswith("RB"):
            if (tagged_sentence[index+2][1].startswith("V") or tagged_sentence[index+2][1].startswith("MD")):
                features_dict["thatresub_029"] += 1 
        elif tagged_sentence[index+1][1].startswith("VB") or tagged_sentence[index+1][1].startswith("MD"):
            features_dict["thatresub_029"] += 1
        elif tagged_sentence[index+1][1].startswith("DT") or tagged_sentence[index+1][1].startswith("JJ") or tagged_sentence[index+1][1] == "NNS" or tagged_sentence[index+1][1].startswith("NNP"):
            features_dict["thatreobj_030"] += 1
        elif tagged_sentence[index+1][0] == "it" or tagged_sentence[index+1][0] in subjpro or tagged_sentence[index+1][0] in posspro:
            features_dict["thatreobj_030"] += 1   
```

- Accuracy: F-score of 0.23

## Gerunds: gerund_015

- Definition from Biber: "All participle forms serving nominal functions - these are edited by hand." (1988: 227)
- Example from Reddit: Does anyone seriously believe that *closing* the source of the OS will reduce piracy? 
- Our search strategy: Within the function analyze_noun we are looking for items ending in <-ing>. These items are then checked against a list of words that we know not to be gerunds. We are therefore deviating from Biber's procedure since a manual analysis was not feasible.
```{python}
notgerundlist = ["nothing", "everything", "something", "anything", "thing", "things", "ring", "sting", "ting", "viking", "wing", "zing"]

    if word_tuple[0].endswith("ing"):
        if word_tuple[0] not in notgerundlist:
            features_dict["gerund_015"] += 1
```

- Accuracy: F-score of 0.235



## Present participial WHIZ deletion relatives: vpresentwhiz_028

- Definition from Biber: "N + VBG (these forms were edited by hand)" (1988: 233)
- Example from Reddit: I don't know... as a mom -- it just looks like a mess *waiting* to happen!!
- Our search strategy: Within the function analyze_verb we are looking for items tagged as "VBG" (Verb, gerund or present participle). We are sorting out structures belonging to vpresentpart_025. If the preceding item is tagged as "NN" (Noun, singular or mass) or "NNS" (Noun, plural) then we are counting the hit towards the feature.
```{python}
    elif word_tuple[1] == "VBG":
        if (tagged_sentence[index-1][1] == "X" or tagged_sentence[index-1][0] in ALLP):
            if tagged_sentence[index+1][1] in ["IN", "DT", "RB", "WP","PRP", "WRB"]:
                features_dict["vpresentpart_025"] += 1
        if (tagged_sentence[index-2][1] == "X" or tagged_sentence[index-2][0] in ALLP):
            if tagged_sentence[index-1][0] in ["while", "without", "when", "although","with"]:
                features_dict["vpresentpart_025"] += 1
        elif tagged_sentence[index-1][1] == "NN" or tagged_sentence[index-1][1] == "NNS": 
            features_dict["vpresentwhiz_028"] += 1 
        elif tagged_sentence[index-1][0] in belist:
            features_dict["vprogressive_217"] += 1
        elif (tagged_sentence[index-2][0] in belist) and (tagged_sentence[index-1][1] == "RB"):
            features_dict["vprogressive_217"] += 1  
            features_dict["vsplitaux_063"] += 1
```

- Accuracy: F-score of 0.352

## Subordinator-that deletion: thatdel_060

- Definition from Biber: 
  "(1) PUB/PRV/SUA + (T#) + demonstrative pro/SUBJPRO 
  (2) PUB/PRV/SUA + PRO/N + AUX/V
  (3) PUB/PRV/SUA + ADJ/ADV/DET/POSSPRO + (ADJ) + N + AUX/V" (1988: 244)
- Example from Reddit: It seems quite freindly though I can *imagine it* would scare some younger kids.
- Our search strategy: Within the function analyze_verb we are first checking whether the verb is part of "publiclist". This list contains surface forms of public verbs as given by Biber. 
  - We count the structure as that-delation if the following item is one of ["this", "these", "those", "I", "we", "he", "she", "they"] (Biber's demonstrative pronouns and subject pronouns). 
  - We also count the structure as that-deletion if the next word is tagged as a noun or pronoun and the word after that is a verb or modal. 
  - We also count the structure as that-deletion if the following item is tagged as one of ["JJ", "JJR", "JJS", "RB", "RBR", "RBS", "PRP$", "DT"] (Biber's adj/adv/det/posspro), the next item is a noun, and the item afterwards is a verb or modal. 
  We are then repeating this procedure for private verbs and suasive verbs (with the same lemmata as given by Biber). 
  The only deviation from Biber is that we are not looking for "that" in the first condition (because of its multifunctionality) and that we are not allowing for an additional interverning adjective in the third condition.
```{python}
    if word_tuple[0] in publiclist:
        if tagged_sentence[index + 1][0] in ["this", "these", "those", "I", "we", "he", "she", "they"]:
            features_dict["thatdel_060"] += 1
        elif tagged_sentence[index + 1][1].startswith("NN") or tagged_sentence[index + 1][1].startswith("PR"):
            if tagged_sentence[index + 2][1].startswith("V") or tagged_sentence[index + 2][1] == "MD":
                features_dict["thatdel_060"] += 1
        elif tagged_sentence[index + 1][1] in ["JJ", "JJR", "JJS", "RB", "RBR", "RBS", "PRP$", "DT"]:
            if tagged_sentence[index + 2][1].startswith("NN"):
                if tagged_sentence[index + 3][1].startswith("V") or tagged_sentence[index + 3][1] == "MD":
                    features_dict["thatdel_060"] += 1

    if word_tuple[0] in privatelist:
        if tagged_sentence[index + 1][0] in ["this", "these", "that", "those", "I", "we", "he", "she", "they"]:
            features_dict["thatdel_060"] += 1
        elif tagged_sentence[index + 1][1].startswith("NN") or tagged_sentence[index + 1][1].startswith("PR"):
            if tagged_sentence[index + 2][1].startswith("V") or tagged_sentence[index + 2][1] == "MD":
                features_dict["thatdel_060"] += 1
        elif tagged_sentence[index + 1][1] in ["JJ", "JJR", "JJS", "RB", "RBR", "RBS", "PRP$", "DT"]:
            if tagged_sentence[index + 2][1].startswith("NN"):
                if tagged_sentence[index + 3][1].startswith("V") or tagged_sentence[index + 3][1] == "MD":
                    features_dict["thatdel_060"] += 1

    if word_tuple[0] in suasivelist:
        if tagged_sentence[index + 1][0] in ["this", "these", "that", "those", "I", "we", "he", "she", "they"]:
            features_dict["thatdel_060"] += 1
        elif tagged_sentence[index + 1][1].startswith("NN") or tagged_sentence[index + 1][1].startswith("PR"):
            if tagged_sentence[index + 2][1].startswith("V") or tagged_sentence[index + 2][1] == "MD":
                features_dict["thatdel_060"] += 1
        elif tagged_sentence[index + 1][1] in ["JJ", "JJR", "JJS", "RB", "RBR", "RBS", "PRP$", "DT"]:
            if tagged_sentence[index + 2][1].startswith("NN"):
                if tagged_sentence[index + 3][1].startswith("V") or tagged_sentence[index + 3][1] == "MD":
                    features_dict["thatdel_060"] += 1
```

- Accuracy: F-score of 0.5



## Present participial clauses: vpresentpart_025

- Definition from Biber: "T#/ALL-P + VBG + PREP/DET/WHP/WHO/PRO/ADV (these forms were edited by hand)" (1988: 233)
- Example from Reddit: With new worlds icons and skins *coming* out this is a great way to get them for free.
- Our search strategy: Within the function analyze_verb we are first checking for items with the tag "VBG" (standing for "Verb, gerund or present participle"). If this item occurs in sentence-initial position and is followed by a word tagged as ["IN", "DT", "RB", "WP","PRP", "WRB"] then it is counted towards this feature. Also if there is ["while", "without", "when", "although","with"] at the start of the sentence followed by the verb itself. This is overall the same strategy as Biber, only that we are including sentences starting with ["while", "without", "when", "although","with"], since these can also be present participial adverbial clauses in sentence-initial position (with overt subject).
```{python}
    elif word_tuple[1] == "VBG":
        if (tagged_sentence[index-1][1] == "X" or tagged_sentence[index-1][0] in ALLP):
            if tagged_sentence[index+1][1] in ["IN", "DT", "RB", "WP","PRP", "WRB"]:
                features_dict["vpresentpart_025"] += 1
        if (tagged_sentence[index-2][1] == "X" or tagged_sentence[index-2][0] in ALLP):
            if tagged_sentence[index-1][0] in ["while", "without", "when", "although","with"]:
                features_dict["vpresentpart_025"] += 1
```

- Accuracy: F-score of 0.533


## Past participial WHIZ deletion relatives: vpastwhiz_027

- Definition from Biber: "N/QUANPRO + VBN + PREP/BE/ADV (these forms were edited by hand)" (1988: 233)
- Example from Reddit: Herbal Phentermine is an exclusive formulation of research-supported botanical ingredients, *designed* to support a healthy diet.
- Our search strategy: Within the function analyze_verb we are first looking for items tagged as "VBN" (Verb, past participle). After sorting out instances belonging the feature vpastpart_026 we check for the following criteria: Is the preceding item tagged as a nouns (all nominal tags start with "NN") or is it within the list QUANPRO? If yes: is the following item tagged as ["IN", "RBR", "RB", "RBS"] or a form of 'be'?
```{python}
    elif word_tuple[1] == "VBN":
        if (tagged_sentence[index-1][1] == "X" or tagged_sentence[index-1][0] in ALLP):
            if tagged_sentence[index+1][1] in ["IN", "RB", "TO"]:
                features_dict["vpastpart_026"] += 1
        elif tagged_sentence[index-1][1].startswith("NN") or tagged_sentence[index-1][0] in QUANPRO:
            if tagged_sentence[index+1][1] in ["IN", "RBR", "RB", "RBS"] or tagged_sentence[index+1][0] in belist:
                features_dict["vpastwhiz_027"] += 1 
```

- Accuracy: F-score of 0.555



## Phrasal coordination: coordphras_064

- Definition from Biber: "xxxx1 + and + xxxx2 (where xxxl and xxx2 are both: ADV/ADJ/V/N)" (1988: 245)
- Example from Reddit: 
    If the people have something, they can use these tactics *and* others to wage a campaign.
- We were unable to come up with a code that can consistently distinguish between all cases of phrasal and non-phrasal coordination, which is why we decided to instead search for coordination with 'and', with 'or', and with 'but" (see above).

## Non-phrasal coordination: coordnonp_065

- Definition from Biber: 
    "(a) T#/, + and + it/so/then/you/there+BE/demonstrative pronoun /SUBJPRO
    (b) CL-P + and
    (c) and + WHP/WHO/adverbial subordinator (nos. 35-8)/discourse particle (no. 50)/conjunct (no. 45)" (1988: 245)
- Example from Reddit: I use it exclusively for porn, *and* it works surprisingly well
- We were unable to come up with a code that can consistently distinguish between all cases of phrasal and non-phrasal coordination, which is why we decided to instead search for coordination with 'and', with 'or', and with 'but" (see above).



# References:
Biber, Douglas. 1988. Variation across speech and writing. Cambridge: Cambridge University Press.
Clarke, Isobelle & Jack Grieve. 2017. Dimensions of Abusive Language on Twitter. In Proceedings of the First Workshop on Abusive Language Online, 1–10. Vancouver.



