## this code should:
- take the monthly files (in txt-format, one commment per line) as input
- for each comment/line, find the additional features (with the help of pre-defined function for each feature)
- save the count for each feature per line into a new txt-file that can be combined with the output of the Biber-tagger

## this code still works on the assumption that one line == one comment
## if we want to split longer comments into their sentences, this would have to be altered

textfile = open("filepath", "r")
resultsfile = open("filepath","w")
linenumber = 0
for line in textfile.readlines():
# split character string into a list
  linenumber += 1
  commentWL = line.split()
# extract the count for each feature with the pre-defined feature-functions
  feature1_counter = apply feature 1 function
  feature2_counter = apply featuer 2 function 
  ...
# print the counts for each comment into a new file
  print(str(linenumber), + ";" + str(feature1_counter) + ";" + str(feature2_counter) + ...)
textfile.close
resultsfile.close



## function for feature 1: hashtags
# iterate over items in the list
counter = 0
for item in WL:
  if "#" in item:
  counter = counter + 1
  else:
    pass
print(counter)

## function for feature 2: URLS (maybe subdivide in u/..., r/..., and www...)
if item.startswith("u/") or item.startswith("r/") or item.startswith("http") or item.startswith("www"):
 

## function for feature 3: capitalisation 
if item.isupper():

## function for feature 4: imperatives

## function for feature 5: comparatives

## function for feature 6: superlatives

## function for feature 7: emoticons

## function for feature 8: question marks


## function for feature 9: exclamation marks

## function for feature 10: strategic lengthening

## function for feature 11: alternating uppercase-lowercase

## function for feature 12: community-specific acronyms/lexical items (such as 'op')


